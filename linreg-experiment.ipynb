{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-14T01:52:26.719778Z","iopub.status.busy":"2022-09-14T01:52:26.718227Z","iopub.status.idle":"2022-09-14T01:52:26.750706Z","shell.execute_reply":"2022-09-14T01:52:26.749722Z","shell.execute_reply.started":"2022-09-14T01:52:26.719601Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: spylls in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (0.1.7)\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: contractions in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (0.1.72)\n","Requirement already satisfied: textsearch>=0.0.21 in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (from contractions) (0.0.21)\n","Requirement already satisfied: anyascii in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n","Requirement already satisfied: pyahocorasick in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: hyphenate in /home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages (1.1.0)\n"]}],"source":["!pip install spylls\n","!pip install contractions\n","!pip install hyphenate"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 07:53:18.907760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 07:53:18.924780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 07:53:18.924791: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["import spacy"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:58:17.282463Z","iopub.status.busy":"2022-09-14T01:58:17.282010Z","iopub.status.idle":"2022-09-14T01:58:17.288648Z","shell.execute_reply":"2022-09-14T01:58:17.287263Z","shell.execute_reply.started":"2022-09-14T01:58:17.282428Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"]}],"source":["from sklearnex import patch_sklearn\n","patch_sklearn()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:23.081076Z","iopub.status.busy":"2022-09-14T02:28:23.080619Z","iopub.status.idle":"2022-09-14T02:28:28.961652Z","shell.execute_reply":"2022-09-14T02:28:28.960286Z","shell.execute_reply.started":"2022-09-14T02:28:23.081039Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from scipy import sparse"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:57:29.770171Z","iopub.status.busy":"2022-09-14T01:57:29.769717Z","iopub.status.idle":"2022-09-14T01:57:29.778008Z","shell.execute_reply":"2022-09-14T01:57:29.775854Z","shell.execute_reply.started":"2022-09-14T01:57:29.770135Z"},"trusted":true},"outputs":[],"source":["from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import ElasticNet\n","\n","from sklearn.kernel_ridge import KernelRidge\n","\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.linear_model import RANSACRegressor\n","\n","from sklearn.linear_model import MultiTaskElasticNet\n","from sklearn.linear_model import MultiTaskLasso"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import HistGradientBoostingRegressor"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:16:47.650819Z","iopub.status.busy":"2022-09-14T02:16:47.650311Z","iopub.status.idle":"2022-09-14T02:16:47.657603Z","shell.execute_reply":"2022-09-14T02:16:47.656745Z","shell.execute_reply.started":"2022-09-14T02:16:47.650699Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:13:25.605062Z","iopub.status.busy":"2022-09-14T02:13:25.604362Z","iopub.status.idle":"2022-09-14T02:13:25.611262Z","shell.execute_reply":"2022-09-14T02:13:25.610369Z","shell.execute_reply.started":"2022-09-14T02:13:25.605009Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","import gc\n","from spylls.hunspell import Dictionary\n","from string import punctuation\n","import re\n","import contractions\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from itertools import chain\n","\n","from hyphenate import hyphenate_word\n","from nltk.tokenize import sent_tokenize"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:10.198882Z","iopub.status.busy":"2022-09-14T01:59:10.198404Z","iopub.status.idle":"2022-09-14T01:59:10.327655Z","shell.execute_reply":"2022-09-14T01:59:10.326340Z","shell.execute_reply.started":"2022-09-14T01:59:10.198840Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"data/train.csv\")\n","test = pd.read_csv(\"data/test.csv\")\n","sample_submission = pd.read_csv(\"data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["simple_logs = pd.DataFrame()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:38.225506Z","iopub.status.busy":"2022-09-14T02:28:38.224755Z","iopub.status.idle":"2022-09-14T02:28:38.232116Z","shell.execute_reply":"2022-09-14T02:28:38.230716Z","shell.execute_reply.started":"2022-09-14T02:28:38.225453Z"},"trusted":true},"outputs":[],"source":["def mcrmse(y_true, y_pred):\n","    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n","    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=0)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:20.373733Z","iopub.status.busy":"2022-09-14T01:59:20.373137Z","iopub.status.idle":"2022-09-14T01:59:20.413000Z","shell.execute_reply":"2022-09-14T01:59:20.411547Z","shell.execute_reply.started":"2022-09-14T01:59:20.373656Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text  cohesion  \\\n","0  0016926B079C  I think that students would benefit from learn...       3.5   \n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n","3  003885A45F42  The best time in life is when you become yours...       4.5   \n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n","\n","   syntax  vocabulary  phraseology  grammar  conventions  \n","0     3.5         3.0          3.0      4.0          3.0  \n","1     2.5         3.0          2.0      2.0          2.5  \n","2     3.5         3.0          3.0      3.0          2.5  \n","3     4.5         4.5          4.5      4.0          5.0  \n","4     3.0         3.0          3.0      2.5          2.5  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train.head(5)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:26.962630Z","iopub.status.busy":"2022-09-14T01:59:26.962208Z","iopub.status.idle":"2022-09-14T01:59:26.975548Z","shell.execute_reply":"2022-09-14T01:59:26.974482Z","shell.execute_reply.started":"2022-09-14T01:59:26.962595Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text\n","0  0000C359D63E  when a person has no experience on a job their...\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:00:10.410947Z","iopub.status.busy":"2022-09-14T02:00:10.410422Z","iopub.status.idle":"2022-09-14T02:00:10.417345Z","shell.execute_reply":"2022-09-14T02:00:10.415902Z","shell.execute_reply.started":"2022-09-14T02:00:10.410904Z"},"trusted":true},"outputs":[],"source":["FEATURE_COLUMNS = ['full_text']\n","TARGET_COLUMNS = ['cohesion', 'syntax','vocabulary', 'phraseology', 'grammar','conventions']"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:18.723880Z","iopub.status.busy":"2022-09-14T02:01:18.723434Z","iopub.status.idle":"2022-09-14T02:01:18.741434Z","shell.execute_reply":"2022-09-14T02:01:18.740473Z","shell.execute_reply.started":"2022-09-14T02:01:18.723847Z"},"trusted":true},"outputs":[],"source":["X, Y = train[FEATURE_COLUMNS], train[TARGET_COLUMNS]\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:43.193744Z","iopub.status.busy":"2022-09-14T02:01:43.193281Z","iopub.status.idle":"2022-09-14T02:01:43.199127Z","shell.execute_reply":"2022-09-14T02:01:43.197919Z","shell.execute_reply.started":"2022-09-14T02:01:43.193704Z"},"trusted":true},"outputs":[],"source":["kfold = KFold(n_splits=5)"]},{"cell_type":"markdown","metadata":{},"source":["#### LinReg\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:33:09.677932Z","iopub.status.busy":"2022-09-14T02:33:09.677446Z","iopub.status.idle":"2022-09-14T02:33:59.671014Z","shell.execute_reply":"2022-09-14T02:33:59.669692Z","shell.execute_reply.started":"2022-09-14T02:33:09.677890Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5541318246499967\n","Fold #1: 0.5537700014592977\n","Fold #2: 0.5470261004584632\n","Fold #3: 0.544407325985179\n","Fold #4: 0.5520343641116121\n","********************************************************************************\n","\n","\tMean loss: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","simple_logs[]\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5709403512789716\n","Fold #1: 0.5726226508335558\n","Fold #2: 0.5635645363980998\n","Fold #3: 0.5632515029920215\n","Fold #4: 0.5698789714147965\n","********************************************************************************\n","\n","\tMean loss: 0.568\n"]}],"source":["# with rounding \n","predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    y_pred = np.round(y_pred*2) / 2\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","    "]},{"cell_type":"markdown","metadata":{},"source":["#### ElasticNet\n","Mean score: .653"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(ElasticNet(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Kernel ridge \n","Mean score: 0.683"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6930777265189026\n","Fold #1: 0.6750998745559542\n","Fold #2: 0.6843776292717582\n","Fold #3: 0.6704404514406113\n","Fold #4: 0.6934175409997669\n","********************************************************************************\n","\n","\tMean loss: 0.683\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(KernelRidge(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Huber\n","Mean score: 0.5478 <br>\n","tfidf (1,2) best"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5515620102984613\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5504950203190537\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5446898913826562\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5419538049081577\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5502569124296768\n","********************************************************************************\n","\n","\tMean score: 0.5478\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6331420093762457\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.630056943661134\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.626796640564493\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.6249290599158402\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.6326062592100771\n","********************************************************************************\n","\n","\tMean score: 0.6295\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5538161068513142\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5509624993104995\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5509353575657568\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5418378324264046\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5560860014742328\n","********************************************************************************\n","\n","\tMean score: 0.5507\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,3))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### MultiTaskLasso\n","Mean score: 0.653"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","    \n","    model = MultiTaskLasso()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    test_vectorized = test_vectorized.toarray()\n","\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Decision Tree\n","Mean score: 0.807"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:36:22.455220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:36:22.471719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:36:22.471730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:36:22.472148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.7931361523412584\n","Fold #1: 0.8144465691907875\n","Fold #2: 0.8023388564277685\n","Fold #3: 0.8114694681488267\n","Fold #4: 0.8132698138502844\n","********************************************************************************\n","\n","\tMean loss: 0.807\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = DecisionTreeRegressor()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest\n","Mean score: 0.569"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = RandomForestRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### XGB\n","Mean score: 0.582"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:58:14.703313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:58:14.721896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:58:14.721910: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:58:14.722549: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5816267489732073\n","Fold #1: 0.5901526685793419\n","Fold #2: 0.5822439205413895\n","Fold #3: 0.5774044165601089\n","Fold #4: 0.5763746517735759\n","********************************************************************************\n","\n","\tMean loss: 0.582\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = XGBRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### LGBM\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5517973919318183\n","Fold #1: 0.5551591652486675\n","Fold #2: 0.5483291446127709\n","Fold #3: 0.5482365804964576\n","Fold #4: 0.5465152434993047\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5569290386975966\n","Fold #1: 0.5516524187961335\n","Fold #2: 0.5498964155109362\n","Fold #3: 0.5458818916232535\n","Fold #4: 0.5478695454500438\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### KNN\n","Mean score: 0.6645"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.671892799169405\n","Fold #1: 0.67549296640102\n","Fold #2: 0.6435011356635894\n","Fold #3: 0.6580667474425836\n","Fold #4: 0.6736422701792272\n","********************************************************************************\n","\n","\tMean score: 0.6645\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = KNeighborsRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### SVR\n","Mean score: 0.5507"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5527417883782569\n","Fold #1: 0.5598486346576218\n","Fold #2: 0.5466700014211566\n","Fold #3: 0.5447914627070536\n","Fold #4: 0.549511123877991\n","********************************************************************************\n","\n","\tMean score: 0.5507\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5534128628705631\n","Fold #1: 0.5568149787750852\n","Fold #2: 0.5462140456365606\n","Fold #3: 0.5468043613997916\n","Fold #4: 0.5493505076755353\n","********************************************************************************\n","\n","\tMean score: 0.5505\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### HistGradient"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5537410728071898\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb Cell 44\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mtoarray(), X_test\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m MultiOutputRegressor(HistGradientBoostingRegressor())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m score_ \u001b[39m=\u001b[39m mcrmse(Y_test, y_pred)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    203\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    204\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     42\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:526\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_trees_per_iteration_):\n\u001b[1;32m    510\u001b[0m     grower \u001b[39m=\u001b[39m TreeGrower(\n\u001b[1;32m    511\u001b[0m         X_binned_train,\n\u001b[1;32m    512\u001b[0m         gradients[k, :],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         n_threads\u001b[39m=\u001b[39mn_threads,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[0;32m--> 526\u001b[0m     grower\u001b[39m.\u001b[39;49mgrow()\n\u001b[1;32m    528\u001b[0m     acc_apply_split_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m grower\u001b[39m.\u001b[39mtotal_apply_split_time\n\u001b[1;32m    529\u001b[0m     acc_find_split_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m grower\u001b[39m.\u001b[39mtotal_find_split_time\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:360\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplittable_nodes:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_next()\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_shrinkage()\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:554\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39m# We use the brute O(n_samples) method on the child that has the\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39m# smallest number of samples, and the subtraction trick O(n_bins)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39m# on the other one.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 554\u001b[0m smallest_child\u001b[39m.\u001b[39mhistograms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhistogram_builder\u001b[39m.\u001b[39;49mcompute_histograms_brute(\n\u001b[1;32m    555\u001b[0m     smallest_child\u001b[39m.\u001b[39;49msample_indices\n\u001b[1;32m    556\u001b[0m )\n\u001b[1;32m    557\u001b[0m largest_child\u001b[39m.\u001b[39mhistograms \u001b[39m=\u001b[39m (\n\u001b[1;32m    558\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistogram_builder\u001b[39m.\u001b[39mcompute_histograms_subtraction(\n\u001b[1;32m    559\u001b[0m         node\u001b[39m.\u001b[39mhistograms, smallest_child\u001b[39m.\u001b[39mhistograms\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_compute_hist_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m tic\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(HistGradientBoostingRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### New features"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["STOPWORDS = set(stopwords.words('english'))\n","DICTIONARY = Dictionary.from_files('en_US')\n","PUNCTUATIONS = set(list(punctuation))\n","PUNCTUATIONS.update(\"`\")\n","PUNCTUATIONS.update(\"'\")\n","CONTRACTIONS = contractions.contractions_dict\n","CONTRACTIONS[\"It'll\"] = \"It will\"\n","CONTRACTIONS = {key.capitalize(): value for key, value in CONTRACTIONS.items()}\n","\n","\n","def check_word(token):\n","    if DICTIONARY.lookup(token):\n","        return 1\n","    else:\n","        return 0\n","\n","def replace_contractions(text):\n","\n","    \n","    for key, value in CONTRACTIONS.items():\n","        # Upper-case\n","        text = text.replace(key, value)\n","        # Lower-case \n","        text = text.replace(key.lower(), value.lower())\n","\n","    # Remove possesives as well \n","    text = text.replace(\"'s\", \"\")\n","\n","    # Remove unnecessary whitespaces\n","    text = re.sub(' +', ' ', text)\n","    \n","    return text \n","\n","\n","def remove_empty_tokens(list_of_tokens):\n","    list_of_tokens = list(filter(None, list_of_tokens))\n","    return list_of_tokens\n","\n","def check_in_dictionary(sentences):\n","\n","    # If the contraction can be removed, than it means it's correct; consequently, only possibly incorrect words remain\n","\n","    tokenized_sentences = word_tokenize(sentences)\n","    correct_tokens = [check_word(token) if (token not in PUNCTUATIONS)  else 1 for token in tokenized_sentences]\n","\n","    return correct_tokens\n","\n","def get_incorrect_indices(correct_word_list):\n","    return [idx for idx, value in enumerate(correct_word_list) if not value]\n","\n","def get_incorrect_words(words_list, indices):\n","    return [words_list[idx] for idx in indices if words_list[idx] ]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["nlp = spacy.load('en_core_web_lg')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def extract_spacy_features(texts):\n","    \n","    tokens = []\n","    poss = []\n","    tags = []\n","    morphs = []\n","    \n","    for doc in nlp.pipe(texts, n_process = -1):\n","        \n","        token_ = []\n","        pos_ = []\n","        tag_ = []\n","        morph_ = []\n","\n","        for token in doc:\n","            token_.append(token.text)\n","            pos_.append(token.pos_)\n","            tag_.append(token.tag_)\n","            morph_.append(token.morph)\n","            \n","        tokens.append(token_)\n","        poss.append(pos_)\n","        tags.append(tag_)\n","        morphs.append(morph_)\n","        \n","    return tokens, poss, tags, morphs"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def extract_verbform(morph):\n","    vbs = []\n","    for i in morph:\n","        vb = i.get('VerbForm')\n","        if vb != []:\n","            vbs.append(vb[0])\n","    return vbs"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def add_new_features(X:pd.DataFrame):\n","    # TODO: replace w/ assign\n","    X['sentences'] = X.full_text.map(sent_tokenize)\n","    X['words'] = X.sentences.apply(lambda sentences: list(chain(*[word_tokenize(sentence) for sentence in sentences])))\n","    X['words'] = X.words.apply(lambda tokens: [token for token in tokens if (token not in PUNCTUATIONS and token != '')])\n","    X['syllables'] = X.words.apply(lambda tokens: list(chain(*[hyphenate_word(token) for token in tokens])))\n","\n","    X['text_'] = X.full_text.map(replace_contractions)\n","    X['tokenized_sentences'] = X.text_.map(word_tokenize)\n","    X['correct_list'] = X.text_.map(check_in_dictionary)\n","    X['incorrect_indices'] = X.correct_list.map(get_incorrect_indices)\n","    X['incorrect_words'] = X.apply(lambda x: get_incorrect_words(x.tokenized_sentences, x.incorrect_indices), axis = 1)\n","\n","    X['incorrect_words_count'] = X.incorrect_words.map(len)\n","\n","    X['sent_count'] = X.sentences.map(len)\n","    X['word_count'] = X.words.map(len)\n","    X['syll_count'] = X.syllables.map(len)\n","\n","    X['words_per_sentences'] = X['sent_count'] / X['word_count']\n","    X['syll_per_sentences'] = X['sent_count'] / X['syll_count'] \n","    X['syll_per_words'] = X['word_count'] / X['syll_count']\n","    X['contains_question'] = X.full_text.str.contains('\\?').astype(int)\n","    \n","    tokens_train, poss_, tags_, morphs_ = extract_spacy_features(X.full_text.values)\n","\n","    X['poss_'] = poss_\n","    X['tag_'] = tags_\n","    X['morph_'] = morphs_\n","\n","    X.poss_ = X.poss_.str.join(' ')\n","\n","    X['VF'] = X.morph_.map(extract_verbform).str.join(' ')\n","\n","    return X"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_270224/1747429121.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['sentences'] = X.full_text.map(sent_tokenize)\n","/tmp/ipykernel_270224/1747429121.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['words'] = X.sentences.apply(lambda sentences: list(chain(*[word_tokenize(sentence) for sentence in sentences])))\n","/tmp/ipykernel_270224/1747429121.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['words'] = X.words.apply(lambda tokens: [token for token in tokens if (token not in PUNCTUATIONS and token != '')])\n","/tmp/ipykernel_270224/1747429121.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['syllables'] = X.words.apply(lambda tokens: list(chain(*[hyphenate_word(token) for token in tokens])))\n","/tmp/ipykernel_270224/1747429121.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['text_'] = X.full_text.map(replace_contractions)\n","/tmp/ipykernel_270224/1747429121.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['tokenized_sentences'] = X.text_.map(word_tokenize)\n","/tmp/ipykernel_270224/1747429121.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X['correct_list'] = X.text_.map(check_in_dictionary)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>sentences</th>\n","      <th>words</th>\n","      <th>syllables</th>\n","      <th>text_</th>\n","      <th>tokenized_sentences</th>\n","      <th>correct_list</th>\n","      <th>incorrect_indices</th>\n","      <th>incorrect_words</th>\n","      <th>...</th>\n","      <th>word_count</th>\n","      <th>syll_count</th>\n","      <th>words_per_sentences</th>\n","      <th>syll_per_sentences</th>\n","      <th>syll_per_words</th>\n","      <th>contains_question</th>\n","      <th>poss_</th>\n","      <th>tag_</th>\n","      <th>morph_</th>\n","      <th>VF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","      <td>[when a person has no experience on a job thei...</td>\n","      <td>[when, a, person, has, no, experience, on, a, ...</td>\n","      <td>[when, a, per, son, has, no, ex, pe, ri, ence,...</td>\n","      <td>when a person has no experience on a job their...</td>\n","      <td>[when, a, person, has, no, experience, on, a, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[23, 43, 45, 82, 103, 123, 125, 182, 213, 215,...</td>\n","      <td>[explane, bassicly, learing, dont, dont, dont,...</td>\n","      <td>...</td>\n","      <td>839</td>\n","      <td>1060</td>\n","      <td>0.030989</td>\n","      <td>0.024528</td>\n","      <td>0.791509</td>\n","      <td>0</td>\n","      <td>SCONJ DET NOUN VERB DET NOUN ADP DET NOUN PRON...</td>\n","      <td>[WRB, DT, NN, VBZ, DT, NN, IN, DT, NN, PRP$, V...</td>\n","      <td>[(), (Definite=Ind, PronType=Art), (Number=Sin...</td>\n","      <td>Fin Fin Part Inf Inf Inf Inf Fin Inf Part Fin ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","      <td>[Do you think students would benefit from bein...</td>\n","      <td>[Do, you, think, students, would, benefit, fro...</td>\n","      <td>[Do, you, think, stu, dents, would, ben, e, fi...</td>\n","      <td>Do you think students would benefit from being...</td>\n","      <td>[Do, you, think, students, would, benefit, fro...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[43, 73, 189, 205, 363, 397]</td>\n","      <td>[ththem, attand, ththem, ththem, attand, ththe...</td>\n","      <td>...</td>\n","      <td>399</td>\n","      <td>523</td>\n","      <td>0.042607</td>\n","      <td>0.032505</td>\n","      <td>0.762906</td>\n","      <td>1</td>\n","      <td>AUX PRON VERB NOUN AUX VERB ADP AUX ADJ VERB N...</td>\n","      <td>[VBP, PRP, VB, NNS, MD, VB, IN, VBG, JJ, VB, N...</td>\n","      <td>[(Mood=Ind, Tense=Pres, VerbForm=Fin), (Case=N...</td>\n","      <td>Fin Inf Fin Inf Ger Inf Fin Fin Inf Fin Fin Fi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","      <td>[Thomas Jefferson once states that \"it is wond...</td>\n","      <td>[Thomas, Jefferson, once, states, that, ``, it...</td>\n","      <td>[Thomas, Jef, fer, son, once, states, that, ``...</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","      <td>[Thomas, Jefferson, once, states, that, ``, it...</td>\n","      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 26, 203, 218]</td>\n","      <td>[``, statthement, '', '']</td>\n","      <td>...</td>\n","      <td>454</td>\n","      <td>590</td>\n","      <td>0.037445</td>\n","      <td>0.028814</td>\n","      <td>0.769492</td>\n","      <td>1</td>\n","      <td>PROPN PROPN ADV VERB SCONJ PUNCT PRON AUX ADJ ...</td>\n","      <td>[NNP, NNP, RB, VBZ, IN, ``, PRP, VBZ, JJ, WRB,...</td>\n","      <td>[(Number=Sing), (Number=Sing), (NumType=Mult),...</td>\n","      <td>Fin Fin Fin Inf Part Fin Part Fin Fin Fin Inf ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows  22 columns</p>\n","</div>"],"text/plain":["        text_id                                          full_text  \\\n","0  0000C359D63E  when a person has no experience on a job their...   \n","1  000BAD50D026  Do you think students would benefit from being...   \n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n","\n","                                           sentences  \\\n","0  [when a person has no experience on a job thei...   \n","1  [Do you think students would benefit from bein...   \n","2  [Thomas Jefferson once states that \"it is wond...   \n","\n","                                               words  \\\n","0  [when, a, person, has, no, experience, on, a, ...   \n","1  [Do, you, think, students, would, benefit, fro...   \n","2  [Thomas, Jefferson, once, states, that, ``, it...   \n","\n","                                           syllables  \\\n","0  [when, a, per, son, has, no, ex, pe, ri, ence,...   \n","1  [Do, you, think, stu, dents, would, ben, e, fi...   \n","2  [Thomas, Jef, fer, son, once, states, that, ``...   \n","\n","                                               text_  \\\n","0  when a person has no experience on a job their...   \n","1  Do you think students would benefit from being...   \n","2  Thomas Jefferson once states that \"it is wonde...   \n","\n","                                 tokenized_sentences  \\\n","0  [when, a, person, has, no, experience, on, a, ...   \n","1  [Do, you, think, students, would, benefit, fro...   \n","2  [Thomas, Jefferson, once, states, that, ``, it...   \n","\n","                                        correct_list  \\\n","0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","2  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","\n","                                   incorrect_indices  \\\n","0  [23, 43, 45, 82, 103, 123, 125, 182, 213, 215,...   \n","1                       [43, 73, 189, 205, 363, 397]   \n","2                                  [5, 26, 203, 218]   \n","\n","                                     incorrect_words  ...  word_count  \\\n","0  [explane, bassicly, learing, dont, dont, dont,...  ...         839   \n","1  [ththem, attand, ththem, ththem, attand, ththe...  ...         399   \n","2                          [``, statthement, '', '']  ...         454   \n","\n","   syll_count  words_per_sentences  syll_per_sentences  syll_per_words  \\\n","0        1060             0.030989            0.024528        0.791509   \n","1         523             0.042607            0.032505        0.762906   \n","2         590             0.037445            0.028814        0.769492   \n","\n","   contains_question                                              poss_  \\\n","0                  0  SCONJ DET NOUN VERB DET NOUN ADP DET NOUN PRON...   \n","1                  1  AUX PRON VERB NOUN AUX VERB ADP AUX ADJ VERB N...   \n","2                  1  PROPN PROPN ADV VERB SCONJ PUNCT PRON AUX ADJ ...   \n","\n","                                                tag_  \\\n","0  [WRB, DT, NN, VBZ, DT, NN, IN, DT, NN, PRP$, V...   \n","1  [VBP, PRP, VB, NNS, MD, VB, IN, VBG, JJ, VB, N...   \n","2  [NNP, NNP, RB, VBZ, IN, ``, PRP, VBZ, JJ, WRB,...   \n","\n","                                              morph_  \\\n","0  [(), (Definite=Ind, PronType=Art), (Number=Sin...   \n","1  [(Mood=Ind, Tense=Pres, VerbForm=Fin), (Case=N...   \n","2  [(Number=Sing), (Number=Sing), (NumType=Mult),...   \n","\n","                                                  VF  \n","0  Fin Fin Part Inf Inf Inf Inf Fin Inf Part Fin ...  \n","1  Fin Inf Fin Inf Ger Inf Fin Fin Inf Fin Fin Fi...  \n","2  Fin Fin Fin Inf Part Fin Part Fin Fin Fin Inf ...  \n","\n","[3 rows x 22 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["add_new_features(X)\n","add_new_features(test)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['text_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n","       'phraseology', 'grammar', 'conventions'],\n","      dtype='object')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train.columns"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["other_features = ['incorrect_words_count', 'sent_count', 'word_count', 'syll_count', 'words_per_sentences', 'syll_per_sentences', 'syll_per_words', 'contains_question']\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Huber: tfidf + other features"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.603293874036087\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5835297339852062\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5845026136418409\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5654080267131697\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5601884935231137\n","********************************************************************************\n","\n","\tMean score: 0.5794\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        vectorized_pos_train,\n","        vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(HuberRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Huber: other features"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5368879184589069\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5403950112805512\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5414899838842435\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5377135881222913\n","Fold #4: 0.52903704439133\n","********************************************************************************\n","\n","\tMean score: 0.5371\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_pos_train,\n","        vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### LGBM: tfidf + other features"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5263995933051274\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5270824233516868\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.526745088384568\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5260794824174228\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5176174900062112\n","********************************************************************************\n","\n","\tMean score: 0.5248\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        vectorized_pos_train,\n","        vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(LGBMRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5449932852683231\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.536311281975003\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5381665761390868\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5318893976477513\n","Fold #4: 0.5305632985315182\n","********************************************************************************\n","\n","\tMean score: 0.5364\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    # pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    # morph_vectorizer = TfidfVectorizer()\n","\n","    # vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    # vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    # vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    # vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    # vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    # vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        # vectorized_pos_train,\n","        # vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        # vectorized_pos_test,\n","        # vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        # vectorized_pos_actual_test,\n","        # vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(LGBMRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5323105830126823\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5331513886951721\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5367470200323461\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5330283111925315\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n","  _log_warning('Converting data to scipy sparse matrix.')\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5250341080636651\n","********************************************************************************\n","\n","\tMean score: 0.5321\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    # other_features_subset_train = X_train[other_features]\n","    # other_features_subset_test = X_test[other_features]\n","    # other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        vectorized_pos_train,\n","        vectorized_morph_train\n","        # other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        # other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test\n","        # other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(LGBMRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### _XGB_"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5611056418969932\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb Cell 66\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m X_actual_test \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mhstack([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     vectorized_text_actual_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     vectorized_pos_actual_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     vectorized_morph_actual_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     other_features_subset_actual_test\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m model \u001b[39m=\u001b[39m XGBRegressor(tree_method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y146sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m score_ \u001b[39m=\u001b[39m mcrmse(Y_test, y_pred)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/xgboost/sklearn.py:961\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    956\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    958\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m    959\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m    960\u001b[0m )\n\u001b[0;32m--> 961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    962\u001b[0m     params,\n\u001b[1;32m    963\u001b[0m     train_dmatrix,\n\u001b[1;32m    964\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m    965\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m    966\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m    967\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m    968\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m    969\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    970\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    971\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    972\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    973\u001b[0m )\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m    976\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1779\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1780\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        vectorized_pos_train,\n","        vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = XGBRegressor(tree_method = 'gpu_hist')\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### SVR"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 07:55:22.899829: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.609460479500206\n","Fold #1: 0.6178598139568953\n","Fold #2: 0.5904801351429326\n","Fold #3: 0.5830384476681263\n","Fold #4: 0.5808801981592673\n","********************************************************************************\n","\n","\tMean score: 0.5963\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","\n","    text_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    vectorized_text_train = text_vectorizer.fit_transform(X_train.full_text.tolist())\n","    vectorized_text_test = text_vectorizer.transform(X_test.full_text.tolist())\n","    vectorized_text_actual_test = text_vectorizer.transform(test.full_text.tolist())\n","\n","    pos_vectorizer = TfidfVectorizer(ngram_range=(1,4))\n","    morph_vectorizer = TfidfVectorizer()\n","\n","    vectorized_pos_train =  pos_vectorizer.fit_transform(X_train.poss_)\n","    vectorized_pos_test =  pos_vectorizer.transform(X_test.poss_)\n","    vectorized_pos_actual_test = pos_vectorizer.transform(test.poss_)\n","\n","    vectorized_morph_train =  morph_vectorizer.fit_transform(X_train.VF)\n","    vectorized_morph_test =  morph_vectorizer.transform(X_test.VF)\n","    vectorized_morph_actual_test =  morph_vectorizer.transform(test.VF)\n","\n","    other_features_subset_train = X_train[other_features]\n","    other_features_subset_test = X_test[other_features]\n","    other_features_subset_actual_test = test[other_features]\n","\n","    X_train = sparse.hstack([\n","        vectorized_text_train,\n","        vectorized_pos_train,\n","        vectorized_morph_train,\n","        other_features_subset_train\n","    ])\n","\n","    X_test = sparse.hstack([\n","        vectorized_text_test,\n","        vectorized_pos_test,\n","        vectorized_morph_test,\n","        other_features_subset_test\n","    ])\n","\n","\n","    X_actual_test = sparse.hstack([\n","        vectorized_text_actual_test,\n","        vectorized_pos_actual_test,\n","        vectorized_morph_actual_test,\n","        other_features_subset_actual_test\n","    ])\n","\n","\n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    \n","    test_prediction = model.predict(X_actual_test)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:38:44.345342Z","iopub.status.busy":"2022-09-14T02:38:44.344877Z","iopub.status.idle":"2022-09-14T02:38:44.351167Z","shell.execute_reply":"2022-09-14T02:38:44.350150Z","shell.execute_reply.started":"2022-09-14T02:38:44.345306Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.066927</td>\n","      <td>2.759472</td>\n","      <td>3.144001</td>\n","      <td>3.051319</td>\n","      <td>2.492089</td>\n","      <td>2.823449</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>2.447473</td>\n","      <td>2.554104</td>\n","      <td>2.579586</td>\n","      <td>2.329913</td>\n","      <td>2.287815</td>\n","      <td>2.528216</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.582943</td>\n","      <td>3.397358</td>\n","      <td>3.529512</td>\n","      <td>3.458739</td>\n","      <td>3.600916</td>\n","      <td>3.366636</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n","0  0000C359D63E  3.066927  2.759472    3.144001     3.051319  2.492089   \n","1  000BAD50D026  2.447473  2.554104    2.579586     2.329913  2.287815   \n","2  00367BB2546B  3.582943  3.397358    3.529512     3.458739  3.600916   \n","\n","   conventions  \n","0     2.823449  \n","1     2.528216  \n","2     3.366636  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["preds_mean = np.mean(predictions, axis = 0)\n","submission = pd.DataFrame()\n","submission.loc[:,'text_id'] = test.text_id\n","submission.loc[:, TARGET_COLUMNS] = preds_mean\n","\n","# submission.loc[:, TARGET_COLUMNS] = (submission.loc[:, TARGET_COLUMNS] * 2).round() / 2\n","submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:50:57.100663Z","iopub.status.busy":"2022-09-14T02:50:57.100192Z","iopub.status.idle":"2022-09-14T02:50:57.109793Z","shell.execute_reply":"2022-09-14T02:50:57.108651Z","shell.execute_reply.started":"2022-09-14T02:50:57.100627Z"},"trusted":true},"outputs":[],"source":["submission.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Score .54 LOL"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.9 ('exp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"vscode":{"interpreter":{"hash":"b7d9b83467eda07c7dcec41582b0623e164b4685431fddd627aa809781990b03"}}},"nbformat":4,"nbformat_minor":4}
