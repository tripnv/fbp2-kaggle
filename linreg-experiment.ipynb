{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-14T01:52:26.719778Z","iopub.status.busy":"2022-09-14T01:52:26.718227Z","iopub.status.idle":"2022-09-14T01:52:26.750706Z","shell.execute_reply":"2022-09-14T01:52:26.749722Z","shell.execute_reply.started":"2022-09-14T01:52:26.719601Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:58:17.282463Z","iopub.status.busy":"2022-09-14T01:58:17.282010Z","iopub.status.idle":"2022-09-14T01:58:17.288648Z","shell.execute_reply":"2022-09-14T01:58:17.287263Z","shell.execute_reply.started":"2022-09-14T01:58:17.282428Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"]}],"source":["from sklearnex import patch_sklearn\n","patch_sklearn()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:23.081076Z","iopub.status.busy":"2022-09-14T02:28:23.080619Z","iopub.status.idle":"2022-09-14T02:28:28.961652Z","shell.execute_reply":"2022-09-14T02:28:28.960286Z","shell.execute_reply.started":"2022-09-14T02:28:23.081039Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:57:29.770171Z","iopub.status.busy":"2022-09-14T01:57:29.769717Z","iopub.status.idle":"2022-09-14T01:57:29.778008Z","shell.execute_reply":"2022-09-14T01:57:29.775854Z","shell.execute_reply.started":"2022-09-14T01:57:29.770135Z"},"trusted":true},"outputs":[],"source":["from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import ElasticNet\n","\n","from sklearn.kernel_ridge import KernelRidge\n","\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.linear_model import RANSACRegressor\n","\n","from sklearn.linear_model import MultiTaskElasticNet\n","from sklearn.linear_model import MultiTaskLasso"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import HistGradientBoostingRegressor"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:16:47.650819Z","iopub.status.busy":"2022-09-14T02:16:47.650311Z","iopub.status.idle":"2022-09-14T02:16:47.657603Z","shell.execute_reply":"2022-09-14T02:16:47.656745Z","shell.execute_reply.started":"2022-09-14T02:16:47.650699Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:13:25.605062Z","iopub.status.busy":"2022-09-14T02:13:25.604362Z","iopub.status.idle":"2022-09-14T02:13:25.611262Z","shell.execute_reply":"2022-09-14T02:13:25.610369Z","shell.execute_reply.started":"2022-09-14T02:13:25.605009Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","import gc"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:10.198882Z","iopub.status.busy":"2022-09-14T01:59:10.198404Z","iopub.status.idle":"2022-09-14T01:59:10.327655Z","shell.execute_reply":"2022-09-14T01:59:10.326340Z","shell.execute_reply.started":"2022-09-14T01:59:10.198840Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"data/train.csv\")\n","test = pd.read_csv(\"data/test.csv\")\n","sample_submission = pd.read_csv(\"data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["simple_logs = pd.DataFrame()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:38.225506Z","iopub.status.busy":"2022-09-14T02:28:38.224755Z","iopub.status.idle":"2022-09-14T02:28:38.232116Z","shell.execute_reply":"2022-09-14T02:28:38.230716Z","shell.execute_reply.started":"2022-09-14T02:28:38.225453Z"},"trusted":true},"outputs":[],"source":["def mcrmse(y_true, y_pred):\n","    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n","    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=0)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:20.373733Z","iopub.status.busy":"2022-09-14T01:59:20.373137Z","iopub.status.idle":"2022-09-14T01:59:20.413000Z","shell.execute_reply":"2022-09-14T01:59:20.411547Z","shell.execute_reply.started":"2022-09-14T01:59:20.373656Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text  cohesion  \\\n","0  0016926B079C  I think that students would benefit from learn...       3.5   \n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n","3  003885A45F42  The best time in life is when you become yours...       4.5   \n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n","\n","   syntax  vocabulary  phraseology  grammar  conventions  \n","0     3.5         3.0          3.0      4.0          3.0  \n","1     2.5         3.0          2.0      2.0          2.5  \n","2     3.5         3.0          3.0      3.0          2.5  \n","3     4.5         4.5          4.5      4.0          5.0  \n","4     3.0         3.0          3.0      2.5          2.5  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train.head(5)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:26.962630Z","iopub.status.busy":"2022-09-14T01:59:26.962208Z","iopub.status.idle":"2022-09-14T01:59:26.975548Z","shell.execute_reply":"2022-09-14T01:59:26.974482Z","shell.execute_reply.started":"2022-09-14T01:59:26.962595Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text\n","0  0000C359D63E  when a person has no experience on a job their...\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:00:10.410947Z","iopub.status.busy":"2022-09-14T02:00:10.410422Z","iopub.status.idle":"2022-09-14T02:00:10.417345Z","shell.execute_reply":"2022-09-14T02:00:10.415902Z","shell.execute_reply.started":"2022-09-14T02:00:10.410904Z"},"trusted":true},"outputs":[],"source":["FEATURE_COLUMNS = ['full_text']\n","TARGET_COLUMNS = ['cohesion', 'syntax','vocabulary', 'phraseology', 'grammar','conventions']"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:18.723880Z","iopub.status.busy":"2022-09-14T02:01:18.723434Z","iopub.status.idle":"2022-09-14T02:01:18.741434Z","shell.execute_reply":"2022-09-14T02:01:18.740473Z","shell.execute_reply.started":"2022-09-14T02:01:18.723847Z"},"trusted":true},"outputs":[],"source":["X, Y = train[FEATURE_COLUMNS], train[TARGET_COLUMNS]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:43.193744Z","iopub.status.busy":"2022-09-14T02:01:43.193281Z","iopub.status.idle":"2022-09-14T02:01:43.199127Z","shell.execute_reply":"2022-09-14T02:01:43.197919Z","shell.execute_reply.started":"2022-09-14T02:01:43.193704Z"},"trusted":true},"outputs":[],"source":["kfold = KFold(n_splits=5)"]},{"cell_type":"markdown","metadata":{},"source":["#### LinReg\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:33:09.677932Z","iopub.status.busy":"2022-09-14T02:33:09.677446Z","iopub.status.idle":"2022-09-14T02:33:59.671014Z","shell.execute_reply":"2022-09-14T02:33:59.669692Z","shell.execute_reply.started":"2022-09-14T02:33:09.677890Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5541318246499967\n","Fold #1: 0.5537700014592977\n","Fold #2: 0.5470261004584632\n","Fold #3: 0.544407325985179\n","Fold #4: 0.5520343641116121\n","********************************************************************************\n","\n","\tMean loss: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","simple_logs[]\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5709403512789716\n","Fold #1: 0.5726226508335558\n","Fold #2: 0.5635645363980998\n","Fold #3: 0.5632515029920215\n","Fold #4: 0.5698789714147965\n","********************************************************************************\n","\n","\tMean loss: 0.568\n"]}],"source":["# with rounding \n","predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    y_pred = np.round(y_pred*2) / 2\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","    "]},{"cell_type":"markdown","metadata":{},"source":["#### ElasticNet\n","Mean score: .653"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(ElasticNet(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Kernel ridge \n","Mean score: 0.683"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6930777265189026\n","Fold #1: 0.6750998745559542\n","Fold #2: 0.6843776292717582\n","Fold #3: 0.6704404514406113\n","Fold #4: 0.6934175409997669\n","********************************************************************************\n","\n","\tMean loss: 0.683\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(KernelRidge(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Huber\n","Mean score: 0.5478 <br>\n","tfidf (1,2) best"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5515620102984613\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5504950203190537\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5446898913826562\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5419538049081577\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5502569124296768\n","********************************************************************************\n","\n","\tMean score: 0.5478\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6331420093762457\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.630056943661134\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.626796640564493\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.6249290599158402\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.6326062592100771\n","********************************************************************************\n","\n","\tMean score: 0.6295\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5538161068513142\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5509624993104995\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5509353575657568\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5418378324264046\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5560860014742328\n","********************************************************************************\n","\n","\tMean score: 0.5507\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,3))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor(max_iter=100))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### MultiTaskLasso\n","Mean score: 0.653"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","    \n","    model = MultiTaskLasso()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    test_vectorized = test_vectorized.toarray()\n","\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Decision Tree\n","Mean score: 0.807"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:36:22.455220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:36:22.471719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:36:22.471730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:36:22.472148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.7931361523412584\n","Fold #1: 0.8144465691907875\n","Fold #2: 0.8023388564277685\n","Fold #3: 0.8114694681488267\n","Fold #4: 0.8132698138502844\n","********************************************************************************\n","\n","\tMean loss: 0.807\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = DecisionTreeRegressor()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest\n","Mean score: 0.569"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = RandomForestRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### XGB\n","Mean score: 0.582"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:58:14.703313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:58:14.721896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:58:14.721910: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:58:14.722549: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5816267489732073\n","Fold #1: 0.5901526685793419\n","Fold #2: 0.5822439205413895\n","Fold #3: 0.5774044165601089\n","Fold #4: 0.5763746517735759\n","********************************************************************************\n","\n","\tMean loss: 0.582\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = XGBRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### LGBM\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5517973919318183\n","Fold #1: 0.5551591652486675\n","Fold #2: 0.5483291446127709\n","Fold #3: 0.5482365804964576\n","Fold #4: 0.5465152434993047\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5569290386975966\n","Fold #1: 0.5516524187961335\n","Fold #2: 0.5498964155109362\n","Fold #3: 0.5458818916232535\n","Fold #4: 0.5478695454500438\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### KNN\n","Mean score: 0.6645"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.671892799169405\n","Fold #1: 0.67549296640102\n","Fold #2: 0.6435011356635894\n","Fold #3: 0.6580667474425836\n","Fold #4: 0.6736422701792272\n","********************************************************************************\n","\n","\tMean score: 0.6645\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = KNeighborsRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### SVR\n","Mean score: 0.5507"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5527417883782569\n","Fold #1: 0.5598486346576218\n","Fold #2: 0.5466700014211566\n","Fold #3: 0.5447914627070536\n","Fold #4: 0.549511123877991\n","********************************************************************************\n","\n","\tMean score: 0.5507\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5534128628705631\n","Fold #1: 0.5568149787750852\n","Fold #2: 0.5462140456365606\n","Fold #3: 0.5468043613997916\n","Fold #4: 0.5493505076755353\n","********************************************************************************\n","\n","\tMean score: 0.5505\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### HistGradient"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5537410728071898\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb Cell 44\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mtoarray(), X_test\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m MultiOutputRegressor(HistGradientBoostingRegressor())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hdd_n/Desktop/hnnaharendt/fbp2-kaggle/linreg-experiment.ipynb#Y106sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m score_ \u001b[39m=\u001b[39m mcrmse(Y_test, y_pred)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    203\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    204\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     42\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:526\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_trees_per_iteration_):\n\u001b[1;32m    510\u001b[0m     grower \u001b[39m=\u001b[39m TreeGrower(\n\u001b[1;32m    511\u001b[0m         X_binned_train,\n\u001b[1;32m    512\u001b[0m         gradients[k, :],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         n_threads\u001b[39m=\u001b[39mn_threads,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[0;32m--> 526\u001b[0m     grower\u001b[39m.\u001b[39;49mgrow()\n\u001b[1;32m    528\u001b[0m     acc_apply_split_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m grower\u001b[39m.\u001b[39mtotal_apply_split_time\n\u001b[1;32m    529\u001b[0m     acc_find_split_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m grower\u001b[39m.\u001b[39mtotal_find_split_time\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:360\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplittable_nodes:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_next()\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_shrinkage()\n","File \u001b[0;32m~/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:554\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39m# We use the brute O(n_samples) method on the child that has the\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39m# smallest number of samples, and the subtraction trick O(n_bins)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39m# on the other one.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 554\u001b[0m smallest_child\u001b[39m.\u001b[39mhistograms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhistogram_builder\u001b[39m.\u001b[39;49mcompute_histograms_brute(\n\u001b[1;32m    555\u001b[0m     smallest_child\u001b[39m.\u001b[39;49msample_indices\n\u001b[1;32m    556\u001b[0m )\n\u001b[1;32m    557\u001b[0m largest_child\u001b[39m.\u001b[39mhistograms \u001b[39m=\u001b[39m (\n\u001b[1;32m    558\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistogram_builder\u001b[39m.\u001b[39mcompute_histograms_subtraction(\n\u001b[1;32m    559\u001b[0m         node\u001b[39m.\u001b[39mhistograms, smallest_child\u001b[39m.\u001b[39mhistograms\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_compute_hist_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m tic\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(HistGradientBoostingRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:38:44.345342Z","iopub.status.busy":"2022-09-14T02:38:44.344877Z","iopub.status.idle":"2022-09-14T02:38:44.351167Z","shell.execute_reply":"2022-09-14T02:38:44.350150Z","shell.execute_reply.started":"2022-09-14T02:38:44.345306Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.066927</td>\n","      <td>2.759472</td>\n","      <td>3.144001</td>\n","      <td>3.051319</td>\n","      <td>2.492089</td>\n","      <td>2.823449</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>2.447473</td>\n","      <td>2.554104</td>\n","      <td>2.579586</td>\n","      <td>2.329913</td>\n","      <td>2.287815</td>\n","      <td>2.528216</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.582943</td>\n","      <td>3.397358</td>\n","      <td>3.529512</td>\n","      <td>3.458739</td>\n","      <td>3.600916</td>\n","      <td>3.366636</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n","0  0000C359D63E  3.066927  2.759472    3.144001     3.051319  2.492089   \n","1  000BAD50D026  2.447473  2.554104    2.579586     2.329913  2.287815   \n","2  00367BB2546B  3.582943  3.397358    3.529512     3.458739  3.600916   \n","\n","   conventions  \n","0     2.823449  \n","1     2.528216  \n","2     3.366636  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["preds_mean = np.mean(predictions, axis = 0)\n","submission = pd.DataFrame()\n","submission.loc[:,'text_id'] = test.text_id\n","submission.loc[:, TARGET_COLUMNS] = preds_mean\n","\n","# submission.loc[:, TARGET_COLUMNS] = (submission.loc[:, TARGET_COLUMNS] * 2).round() / 2\n","submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:50:57.100663Z","iopub.status.busy":"2022-09-14T02:50:57.100192Z","iopub.status.idle":"2022-09-14T02:50:57.109793Z","shell.execute_reply":"2022-09-14T02:50:57.108651Z","shell.execute_reply.started":"2022-09-14T02:50:57.100627Z"},"trusted":true},"outputs":[],"source":["submission.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Score .54 LOL"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.9 ('exp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"vscode":{"interpreter":{"hash":"b7d9b83467eda07c7dcec41582b0623e164b4685431fddd627aa809781990b03"}}},"nbformat":4,"nbformat_minor":4}
