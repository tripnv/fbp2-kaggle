{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-14T01:52:26.719778Z","iopub.status.busy":"2022-09-14T01:52:26.718227Z","iopub.status.idle":"2022-09-14T01:52:26.750706Z","shell.execute_reply":"2022-09-14T01:52:26.749722Z","shell.execute_reply.started":"2022-09-14T01:52:26.719601Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:58:17.282463Z","iopub.status.busy":"2022-09-14T01:58:17.282010Z","iopub.status.idle":"2022-09-14T01:58:17.288648Z","shell.execute_reply":"2022-09-14T01:58:17.287263Z","shell.execute_reply.started":"2022-09-14T01:58:17.282428Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"]}],"source":["from sklearnex import patch_sklearn\n","patch_sklearn()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:23.081076Z","iopub.status.busy":"2022-09-14T02:28:23.080619Z","iopub.status.idle":"2022-09-14T02:28:28.961652Z","shell.execute_reply":"2022-09-14T02:28:28.960286Z","shell.execute_reply.started":"2022-09-14T02:28:23.081039Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:57:29.770171Z","iopub.status.busy":"2022-09-14T01:57:29.769717Z","iopub.status.idle":"2022-09-14T01:57:29.778008Z","shell.execute_reply":"2022-09-14T01:57:29.775854Z","shell.execute_reply.started":"2022-09-14T01:57:29.770135Z"},"trusted":true},"outputs":[],"source":["from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import ElasticNet\n","\n","from sklearn.kernel_ridge import KernelRidge\n","\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.linear_model import RANSACRegressor\n","\n","from sklearn.linear_model import MultiTaskElasticNet\n","from sklearn.linear_model import MultiTaskLasso"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import HistGradientBoostingRegressor"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:16:47.650819Z","iopub.status.busy":"2022-09-14T02:16:47.650311Z","iopub.status.idle":"2022-09-14T02:16:47.657603Z","shell.execute_reply":"2022-09-14T02:16:47.656745Z","shell.execute_reply.started":"2022-09-14T02:16:47.650699Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:13:25.605062Z","iopub.status.busy":"2022-09-14T02:13:25.604362Z","iopub.status.idle":"2022-09-14T02:13:25.611262Z","shell.execute_reply":"2022-09-14T02:13:25.610369Z","shell.execute_reply.started":"2022-09-14T02:13:25.605009Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","import gc"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:10.198882Z","iopub.status.busy":"2022-09-14T01:59:10.198404Z","iopub.status.idle":"2022-09-14T01:59:10.327655Z","shell.execute_reply":"2022-09-14T01:59:10.326340Z","shell.execute_reply.started":"2022-09-14T01:59:10.198840Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"data/train.csv\")\n","test = pd.read_csv(\"data/test.csv\")\n","sample_submission = pd.read_csv(\"data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["simple_logs = pd.DataFrame()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:28:38.225506Z","iopub.status.busy":"2022-09-14T02:28:38.224755Z","iopub.status.idle":"2022-09-14T02:28:38.232116Z","shell.execute_reply":"2022-09-14T02:28:38.230716Z","shell.execute_reply.started":"2022-09-14T02:28:38.225453Z"},"trusted":true},"outputs":[],"source":["def mcrmse(y_true, y_pred):\n","    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n","    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=0)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:20.373733Z","iopub.status.busy":"2022-09-14T01:59:20.373137Z","iopub.status.idle":"2022-09-14T01:59:20.413000Z","shell.execute_reply":"2022-09-14T01:59:20.411547Z","shell.execute_reply.started":"2022-09-14T01:59:20.373656Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text  cohesion  \\\n","0  0016926B079C  I think that students would benefit from learn...       3.5   \n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n","3  003885A45F42  The best time in life is when you become yours...       4.5   \n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n","\n","   syntax  vocabulary  phraseology  grammar  conventions  \n","0     3.5         3.0          3.0      4.0          3.0  \n","1     2.5         3.0          2.0      2.0          2.5  \n","2     3.5         3.0          3.0      3.0          2.5  \n","3     4.5         4.5          4.5      4.0          5.0  \n","4     3.0         3.0          3.0      2.5          2.5  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train.head(5)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T01:59:26.962630Z","iopub.status.busy":"2022-09-14T01:59:26.962208Z","iopub.status.idle":"2022-09-14T01:59:26.975548Z","shell.execute_reply":"2022-09-14T01:59:26.974482Z","shell.execute_reply.started":"2022-09-14T01:59:26.962595Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text\n","0  0000C359D63E  when a person has no experience on a job their...\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:00:10.410947Z","iopub.status.busy":"2022-09-14T02:00:10.410422Z","iopub.status.idle":"2022-09-14T02:00:10.417345Z","shell.execute_reply":"2022-09-14T02:00:10.415902Z","shell.execute_reply.started":"2022-09-14T02:00:10.410904Z"},"trusted":true},"outputs":[],"source":["FEATURE_COLUMNS = ['full_text']\n","TARGET_COLUMNS = ['cohesion', 'syntax','vocabulary', 'phraseology', 'grammar','conventions']"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:18.723880Z","iopub.status.busy":"2022-09-14T02:01:18.723434Z","iopub.status.idle":"2022-09-14T02:01:18.741434Z","shell.execute_reply":"2022-09-14T02:01:18.740473Z","shell.execute_reply.started":"2022-09-14T02:01:18.723847Z"},"trusted":true},"outputs":[],"source":["X, Y = train[FEATURE_COLUMNS], train[TARGET_COLUMNS]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:01:43.193744Z","iopub.status.busy":"2022-09-14T02:01:43.193281Z","iopub.status.idle":"2022-09-14T02:01:43.199127Z","shell.execute_reply":"2022-09-14T02:01:43.197919Z","shell.execute_reply.started":"2022-09-14T02:01:43.193704Z"},"trusted":true},"outputs":[],"source":["kfold = KFold(n_splits=5)"]},{"cell_type":"markdown","metadata":{},"source":["#### LinReg\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:33:09.677932Z","iopub.status.busy":"2022-09-14T02:33:09.677446Z","iopub.status.idle":"2022-09-14T02:33:59.671014Z","shell.execute_reply":"2022-09-14T02:33:59.669692Z","shell.execute_reply.started":"2022-09-14T02:33:09.677890Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5541318246499967\n","Fold #1: 0.5537700014592977\n","Fold #2: 0.5470261004584632\n","Fold #3: 0.544407325985179\n","Fold #4: 0.5520343641116121\n","********************************************************************************\n","\n","\tMean loss: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","simple_logs[]\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5709403512789716\n","Fold #1: 0.5726226508335558\n","Fold #2: 0.5635645363980998\n","Fold #3: 0.5632515029920215\n","Fold #4: 0.5698789714147965\n","********************************************************************************\n","\n","\tMean loss: 0.568\n"]}],"source":["# with rounding \n","predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LinearRegression(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    y_pred = np.round(y_pred*2) / 2\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")\n","    "]},{"cell_type":"markdown","metadata":{},"source":["#### ElasticNet\n","Mean score: .653"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(ElasticNet(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Kernel ridge \n","Mean score: 0.683"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6930777265189026\n","Fold #1: 0.6750998745559542\n","Fold #2: 0.6843776292717582\n","Fold #3: 0.6704404514406113\n","Fold #4: 0.6934175409997669\n","********************************************************************************\n","\n","\tMean loss: 0.683\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    # X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(KernelRidge(), n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    # test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Huber\n","Mean score: 0.548"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","2022-09-15 04:19:17.488334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:19:17.521087: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:19:17.521103: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:19:17.521501: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5515620102984613\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #1: 0.5504950203190537\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #2: 0.5446898913826562\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #3: 0.5419538049081577\n"]},{"name":"stderr","output_type":"stream","text":["/home/hdd_n/mambaforge/envs/exp/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]},{"name":"stdout","output_type":"stream","text":["Fold #4: 0.5502569124296768\n","********************************************************************************\n","\n","\tMean loss: 0.548\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(HuberRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### MultiTaskLasso\n","Mean score: 0.653"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.6528782028635198\n","Fold #1: 0.6741904406848621\n","Fold #2: 0.6446424251073121\n","Fold #3: 0.6458552901536275\n","Fold #4: 0.6467219977663213\n","********************************************************************************\n","\n","\tMean loss: 0.653\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","    \n","    model = MultiTaskLasso()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    test_vectorized = test_vectorized.toarray()\n","\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Decision Tree\n","Mean score: 0.807"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:36:22.455220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:36:22.471719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:36:22.471730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:36:22.472148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.7931361523412584\n","Fold #1: 0.8144465691907875\n","Fold #2: 0.8023388564277685\n","Fold #3: 0.8114694681488267\n","Fold #4: 0.8132698138502844\n","********************************************************************************\n","\n","\tMean loss: 0.807\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = DecisionTreeRegressor()\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest\n","Mean score: 0.569"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = RandomForestRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### XGB\n","Mean score: 0.582"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-15 04:58:14.703313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-15 04:58:14.721896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-09-15 04:58:14.721910: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-09-15 04:58:14.722549: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5816267489732073\n","Fold #1: 0.5901526685793419\n","Fold #2: 0.5822439205413895\n","Fold #3: 0.5774044165601089\n","Fold #4: 0.5763746517735759\n","********************************************************************************\n","\n","\tMean loss: 0.582\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = XGBRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### LGBM\n","Mean score: 0.550"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5517973919318183\n","Fold #1: 0.5551591652486675\n","Fold #2: 0.5483291446127709\n","Fold #3: 0.5482365804964576\n","Fold #4: 0.5465152434993047\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5569290386975966\n","Fold #1: 0.5516524187961335\n","Fold #2: 0.5498964155109362\n","Fold #3: 0.5458818916232535\n","Fold #4: 0.5478695454500438\n","********************************************************************************\n","\n","\tMean score: 0.550\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1))\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### KNN\n","Mean score: 0.6645"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.671892799169405\n","Fold #1: 0.67549296640102\n","Fold #2: 0.6435011356635894\n","Fold #3: 0.6580667474425836\n","Fold #4: 0.6736422701792272\n","********************************************************************************\n","\n","\tMean score: 0.6645\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = KNeighborsRegressor(n_jobs = -1)\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### SVR\n","Mean score: 0.5507"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5527417883782569\n","Fold #1: 0.5598486346576218\n","Fold #2: 0.5466700014211566\n","Fold #3: 0.5447914627070536\n","Fold #4: 0.549511123877991\n","********************************************************************************\n","\n","\tMean score: 0.5507\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,2))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5534128628705631\n","Fold #1: 0.5568149787750852\n","Fold #2: 0.5462140456365606\n","Fold #3: 0.5468043613997916\n","Fold #4: 0.5493505076755353\n","********************************************************************************\n","\n","\tMean score: 0.5505\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    \n","    model = MultiOutputRegressor(SVR())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### HistGradient"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold #0: 0.5537410728071898\n"]}],"source":["predictions = []\n","scores = []\n","for idx, (train_index, test_index) in enumerate(kfold.split(X)):\n","    X_train, X_test, Y_train, Y_test = X.iloc[train_index], X.iloc[test_index], Y.iloc[train_index], Y.iloc[test_index]\n","    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n","    X_train = vectorizer.fit_transform(X_train.full_text.tolist())\n","    X_test = vectorizer.transform(X_test.full_text.tolist())\n","    X_train, X_test = X_train.toarray(), X_test.toarray()\n","\n","    model = MultiOutputRegressor(HistGradientBoostingRegressor())\n","    model.fit(X_train, Y_train)\n","    y_pred = model.predict(X_test)\n","    score_ = mcrmse(Y_test, y_pred)\n","    scores.append(score_)\n","    print(f\"Fold #{idx}: {score_}\")\n","    \n","    test_vectorized = vectorizer.transform(test.full_text.tolist())\n","    test_vectorized = test_vectorized.toarray()\n","    test_prediction = model.predict(test_vectorized)\n","    predictions.append(test_prediction)\n","    \n","print (80*'*')\n","print(f\"\\n\\tMean score: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:38:44.345342Z","iopub.status.busy":"2022-09-14T02:38:44.344877Z","iopub.status.idle":"2022-09-14T02:38:44.351167Z","shell.execute_reply":"2022-09-14T02:38:44.350150Z","shell.execute_reply.started":"2022-09-14T02:38:44.345306Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.066927</td>\n","      <td>2.759472</td>\n","      <td>3.144001</td>\n","      <td>3.051319</td>\n","      <td>2.492089</td>\n","      <td>2.823449</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>2.447473</td>\n","      <td>2.554104</td>\n","      <td>2.579586</td>\n","      <td>2.329913</td>\n","      <td>2.287815</td>\n","      <td>2.528216</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.582943</td>\n","      <td>3.397358</td>\n","      <td>3.529512</td>\n","      <td>3.458739</td>\n","      <td>3.600916</td>\n","      <td>3.366636</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n","0  0000C359D63E  3.066927  2.759472    3.144001     3.051319  2.492089   \n","1  000BAD50D026  2.447473  2.554104    2.579586     2.329913  2.287815   \n","2  00367BB2546B  3.582943  3.397358    3.529512     3.458739  3.600916   \n","\n","   conventions  \n","0     2.823449  \n","1     2.528216  \n","2     3.366636  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["preds_mean = np.mean(predictions, axis = 0)\n","submission = pd.DataFrame()\n","submission.loc[:,'text_id'] = test.text_id\n","submission.loc[:, TARGET_COLUMNS] = preds_mean\n","\n","# submission.loc[:, TARGET_COLUMNS] = (submission.loc[:, TARGET_COLUMNS] * 2).round() / 2\n","submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T02:50:57.100663Z","iopub.status.busy":"2022-09-14T02:50:57.100192Z","iopub.status.idle":"2022-09-14T02:50:57.109793Z","shell.execute_reply":"2022-09-14T02:50:57.108651Z","shell.execute_reply.started":"2022-09-14T02:50:57.100627Z"},"trusted":true},"outputs":[],"source":["submission.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Score .54 LOL"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.9 ('exp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"vscode":{"interpreter":{"hash":"b7d9b83467eda07c7dcec41582b0623e164b4685431fddd627aa809781990b03"}}},"nbformat":4,"nbformat_minor":4}
