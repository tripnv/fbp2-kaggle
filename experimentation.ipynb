{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 09:30:08.901949: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train.csv'\n",
    "TEST_PATH = 'data/test.csv'\n",
    "SAMPLE_SUBMISSION = 'data/sample_submission.csv'\n",
    "RANDOM_STATE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = ['full_text']\n",
    "TARGET_COLUMNS = ['cohesion', 'syntax','vocabulary', 'phraseology', 'grammar','conventions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.321276595744681"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chollet transformer heuristic\n",
    "# S = number of samples / mean number of words per sample\n",
    "# if S > 1500 --> Sequence model\n",
    "# else --> bag-of-bigrams\n",
    "\n",
    "tokenized_sentences = train.full_text.map(word_tokenize)\n",
    "mean_number_of_tokens = tokenized_sentences.map(len).mean().round()\n",
    "S = train.shape[0] / mean_number_of_tokens\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3911, 8), (3, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3128, 1), (587, 1), (196, 1), (3128, 6), (587, 6), (196, 6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = train[FEATURE_COLUMNS], train[TARGET_COLUMNS]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2)\n",
    "\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test, Y_test, test_size=.25)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape, Y_train.shape, Y_valid.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 20000\n",
    "tokenizer = Tokenizer(num_words= max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train.full_text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer.texts_to_sequences(X_train.full_text)\n",
    "tokenized_valid = tokenizer.texts_to_sequences(X_valid.full_text)\n",
    "tokenized_test = tokenizer.texts_to_sequences(X_test.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train = pad_sequences(sequences=tokenized_train, maxlen = 1000)\n",
    "padded_valid = pad_sequences(sequences=tokenized_valid, maxlen = 1000)\n",
    "padded_test = pad_sequences(sequences=tokenized_test, maxlen = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3128, 1000), (587, 1000), (196, 1000))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape, padded_valid.shape, padded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membeddings_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras.layers.Embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Turns positive integers (indexes) into dense vectors of fixed size.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  This layer can only be used on positive integer inputs of a fixed range. The\u001b[0m\n",
      "\u001b[0;34m  `tf.keras.layers.TextVectorization`, `tf.keras.layers.StringLookup`,\u001b[0m\n",
      "\u001b[0;34m  and `tf.keras.layers.IntegerLookup` preprocessing layers can help prepare\u001b[0m\n",
      "\u001b[0;34m  inputs for an `Embedding` layer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  This layer accepts `tf.Tensor` and `tf.RaggedTensor` inputs. It cannot be\u001b[0m\n",
      "\u001b[0;34m  called with `tf.SparseTensor` input.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> model = tf.keras.Sequential()\u001b[0m\n",
      "\u001b[0;34m  >>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\u001b[0m\n",
      "\u001b[0;34m  >>> # The model will take as input an integer matrix of size (batch,\u001b[0m\n",
      "\u001b[0;34m  >>> # input_length), and the largest integer (i.e. word index) in the input\u001b[0m\n",
      "\u001b[0;34m  >>> # should be no larger than 999 (vocabulary size).\u001b[0m\n",
      "\u001b[0;34m  >>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\u001b[0m\n",
      "\u001b[0;34m  >>> # dimension.\u001b[0m\n",
      "\u001b[0;34m  >>> input_array = np.random.randint(1000, size=(32, 10))\u001b[0m\n",
      "\u001b[0;34m  >>> model.compile('rmsprop', 'mse')\u001b[0m\n",
      "\u001b[0;34m  >>> output_array = model.predict(input_array)\u001b[0m\n",
      "\u001b[0;34m  >>> print(output_array.shape)\u001b[0m\n",
      "\u001b[0;34m  (32, 10, 64)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Args:\u001b[0m\n",
      "\u001b[0;34m    input_dim: Integer. Size of the vocabulary,\u001b[0m\n",
      "\u001b[0;34m      i.e. maximum integer index + 1.\u001b[0m\n",
      "\u001b[0;34m    output_dim: Integer. Dimension of the dense embedding.\u001b[0m\n",
      "\u001b[0;34m    embeddings_initializer: Initializer for the `embeddings`\u001b[0m\n",
      "\u001b[0;34m      matrix (see `keras.initializers`).\u001b[0m\n",
      "\u001b[0;34m    embeddings_regularizer: Regularizer function applied to\u001b[0m\n",
      "\u001b[0;34m      the `embeddings` matrix (see `keras.regularizers`).\u001b[0m\n",
      "\u001b[0;34m    embeddings_constraint: Constraint function applied to\u001b[0m\n",
      "\u001b[0;34m      the `embeddings` matrix (see `keras.constraints`).\u001b[0m\n",
      "\u001b[0;34m    mask_zero: Boolean, whether or not the input value 0 is a special \"padding\"\u001b[0m\n",
      "\u001b[0;34m      value that should be masked out.\u001b[0m\n",
      "\u001b[0;34m      This is useful when using recurrent layers\u001b[0m\n",
      "\u001b[0;34m      which may take variable length input.\u001b[0m\n",
      "\u001b[0;34m      If this is `True`, then all subsequent layers\u001b[0m\n",
      "\u001b[0;34m      in the model need to support masking or an exception will be raised.\u001b[0m\n",
      "\u001b[0;34m      If mask_zero is set to True, as a consequence, index 0 cannot be\u001b[0m\n",
      "\u001b[0;34m      used in the vocabulary (input_dim should equal size of\u001b[0m\n",
      "\u001b[0;34m      vocabulary + 1).\u001b[0m\n",
      "\u001b[0;34m    input_length: Length of input sequences, when it is constant.\u001b[0m\n",
      "\u001b[0;34m      This argument is required if you are going to connect\u001b[0m\n",
      "\u001b[0;34m      `Flatten` then `Dense` layers upstream\u001b[0m\n",
      "\u001b[0;34m      (without it, the shape of the dense outputs cannot be computed).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Input shape:\u001b[0m\n",
      "\u001b[0;34m    2D tensor with shape: `(batch_size, input_length)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Output shape:\u001b[0m\n",
      "\u001b[0;34m    3D tensor with shape: `(batch_size, input_length, output_dim)`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **Note on variable placement:**\u001b[0m\n",
      "\u001b[0;34m  By default, if a GPU is available, the embedding matrix will be placed on\u001b[0m\n",
      "\u001b[0;34m  the GPU. This achieves the best performance, but it might cause issues:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  - You may be using an optimizer that does not support sparse GPU kernels.\u001b[0m\n",
      "\u001b[0;34m  In this case you will see an error upon training your model.\u001b[0m\n",
      "\u001b[0;34m  - Your embedding matrix may be too large to fit on your GPU. In this case\u001b[0m\n",
      "\u001b[0;34m  you will see an Out Of Memory (OOM) error.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  In such cases, you should place the embedding matrix on the CPU memory.\u001b[0m\n",
      "\u001b[0;34m  You can do so with a device scope, as such:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  with tf.device('cpu:0'):\u001b[0m\n",
      "\u001b[0;34m    embedding_layer = Embedding(...)\u001b[0m\n",
      "\u001b[0;34m    embedding_layer.build()\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The pre-built `embedding_layer` instance can then be added to a `Sequential`\u001b[0m\n",
      "\u001b[0;34m  model (e.g. `model.add(embedding_layer)`), called in a Functional model\u001b[0m\n",
      "\u001b[0;34m  (e.g. `x = embedding_layer(x)`), or used in a subclassed model.\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_initializer_layout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0membeddings_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m'input_shape'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m'Both `input_dim` and `output_dim` should be positive, '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf'Received input_dim = {input_dim} and output_dim = {output_dim}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2_dtype_behavior_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'dtype'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# In TF1, the dtype defaults to the input dtype which is typically int32,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# so explicitly set it to floatx\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# We set autocast to False, as we do not want to cast floating- point inputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# to self.dtype. In call(), we cast to int32, and casting to self.dtype\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# before casting to int32 might cause the int32 values to be different due\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# to a loss of precision.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'autocast'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'embeddings'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mexperimental_autocast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# input_length can be tuple if input is 3D or higher\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0min_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0min_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf'\"input_length\" is {self.input_length}, but received input has '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf'shape {input_shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf'\"input_length\" is {self.input_length}, but received input '\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf'has shape {input_shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32melif\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0min_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Instead of casting the variable as in most layers, cast the output, as\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# this is mathematically equivalent but is faster.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'input_dim'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'output_dim'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'embeddings_initializer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'embeddings_regularizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'activity_regularizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'embeddings_constraint'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'mask_zero'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_zero\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'input_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/mambaforge/envs/tf_env/lib/python3.10/site-packages/keras/layers/core/embedding.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "??tf.keras.layers.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: A 3D tensor, with shape [batch, timesteps, feature].\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = max_tokens, output_dim = 64, input_length = 1000),\n",
    "    tf.keras.layers.Conv1D(16, kernel_size = 7),\n",
    "    tf.keras.layers.Conv1D(8, kernel_size = 7),\n",
    "    tf.keras.layers.Dropout(.45),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdd_n/mambaforge/envs/tf_env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = MCRMSE, metrics = 'mse', optimizer = tf.keras.optimizers.RMSprop(lr = 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, 1000, 64)          1280000   \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 994, 16)           7184      \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 988, 8)            904       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 988, 8)            0         \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 7904)              0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 6)                 47430     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,335,518\n",
      "Trainable params: 1,335,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_scratch.keras\", save_best_only=True), \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = 50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "98/98 [==============================] - 1s 4ms/step - loss: 3.1067 - mse: 9.6825 - val_loss: 3.1312 - val_mse: 9.8330\n",
      "Epoch 2/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 3.0675 - mse: 9.4399 - val_loss: 3.0918 - val_mse: 9.5888\n",
      "Epoch 3/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 3.0270 - mse: 9.1944 - val_loss: 3.0506 - val_mse: 9.3364\n",
      "Epoch 4/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.9832 - mse: 8.9339 - val_loss: 3.0073 - val_mse: 9.0752\n",
      "Epoch 5/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.9405 - mse: 8.6810 - val_loss: 2.9618 - val_mse: 8.8044\n",
      "Epoch 6/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.8897 - mse: 8.3849 - val_loss: 2.9136 - val_mse: 8.5224\n",
      "Epoch 7/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 2.8442 - mse: 8.1245 - val_loss: 2.8631 - val_mse: 8.2317\n",
      "Epoch 8/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.7894 - mse: 7.8204 - val_loss: 2.8100 - val_mse: 7.9312\n",
      "Epoch 9/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.7361 - mse: 7.5232 - val_loss: 2.7545 - val_mse: 7.6236\n",
      "Epoch 10/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 2.6766 - mse: 7.2034 - val_loss: 2.6959 - val_mse: 7.3054\n",
      "Epoch 11/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 2.6149 - mse: 6.8777 - val_loss: 2.6351 - val_mse: 6.9826\n",
      "Epoch 12/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 2.5499 - mse: 6.5450 - val_loss: 2.5715 - val_mse: 6.6528\n",
      "Epoch 13/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 2.4891 - mse: 6.2395 - val_loss: 2.5053 - val_mse: 6.3179\n",
      "Epoch 14/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.4183 - mse: 5.8939 - val_loss: 2.4368 - val_mse: 5.9805\n",
      "Epoch 15/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.3476 - mse: 5.5555 - val_loss: 2.3655 - val_mse: 5.6390\n",
      "Epoch 16/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.2743 - mse: 5.2216 - val_loss: 2.2918 - val_mse: 5.2973\n",
      "Epoch 17/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.1973 - mse: 4.8803 - val_loss: 2.2159 - val_mse: 4.9562\n",
      "Epoch 18/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 2.1238 - mse: 4.5560 - val_loss: 2.1378 - val_mse: 4.6172\n",
      "Epoch 19/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 2.0429 - mse: 4.2220 - val_loss: 2.0577 - val_mse: 4.2820\n",
      "Epoch 20/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.9605 - mse: 3.8943 - val_loss: 1.9760 - val_mse: 3.9535\n",
      "Epoch 21/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.8777 - mse: 3.5771 - val_loss: 1.8931 - val_mse: 3.6333\n",
      "Epoch 22/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.7947 - mse: 3.2695 - val_loss: 1.8097 - val_mse: 3.3245\n",
      "Epoch 23/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.7126 - mse: 2.9811 - val_loss: 1.7260 - val_mse: 3.0286\n",
      "Epoch 24/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.6240 - mse: 2.6919 - val_loss: 1.6429 - val_mse: 2.7481\n",
      "Epoch 25/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.5443 - mse: 2.4389 - val_loss: 1.5617 - val_mse: 2.4868\n",
      "Epoch 26/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.4645 - mse: 2.2006 - val_loss: 1.4838 - val_mse: 2.2476\n",
      "Epoch 27/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.3960 - mse: 1.9897 - val_loss: 1.4100 - val_mse: 2.0317\n",
      "Epoch 28/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3271 - mse: 1.8014 - val_loss: 1.3429 - val_mse: 1.8443\n",
      "Epoch 29/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.2645 - mse: 1.6414 - val_loss: 1.2825 - val_mse: 1.6825\n",
      "Epoch 30/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.2145 - mse: 1.5090 - val_loss: 1.2314 - val_mse: 1.5513\n",
      "Epoch 31/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1724 - mse: 1.4099 - val_loss: 1.1899 - val_mse: 1.4481\n",
      "Epoch 32/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1416 - mse: 1.3333 - val_loss: 1.1580 - val_mse: 1.3712\n",
      "Epoch 33/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1221 - mse: 1.2847 - val_loss: 1.1346 - val_mse: 1.3161\n",
      "Epoch 34/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1033 - mse: 1.2417 - val_loss: 1.1161 - val_mse: 1.2734\n",
      "Epoch 35/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0886 - mse: 1.2172 - val_loss: 1.1014 - val_mse: 1.2401\n",
      "Epoch 36/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0773 - mse: 1.1919 - val_loss: 1.0887 - val_mse: 1.2116\n",
      "Epoch 37/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0662 - mse: 1.1632 - val_loss: 1.0773 - val_mse: 1.1866\n",
      "Epoch 38/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.0590 - mse: 1.1461 - val_loss: 1.0665 - val_mse: 1.1630\n",
      "Epoch 39/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.0472 - mse: 1.1219 - val_loss: 1.0567 - val_mse: 1.1419\n",
      "Epoch 40/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 1.0364 - mse: 1.1005 - val_loss: 1.0470 - val_mse: 1.1213\n",
      "Epoch 41/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0291 - mse: 1.0811 - val_loss: 1.0375 - val_mse: 1.1011\n",
      "Epoch 42/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0198 - mse: 1.0620 - val_loss: 1.0281 - val_mse: 1.0815\n",
      "Epoch 43/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0096 - mse: 1.0445 - val_loss: 1.0193 - val_mse: 1.0632\n",
      "Epoch 44/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0006 - mse: 1.0252 - val_loss: 1.0108 - val_mse: 1.0458\n",
      "Epoch 45/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9934 - mse: 1.0128 - val_loss: 1.0027 - val_mse: 1.0292\n",
      "Epoch 46/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9867 - mse: 0.9978 - val_loss: 0.9944 - val_mse: 1.0124\n",
      "Epoch 47/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9795 - mse: 0.9864 - val_loss: 0.9868 - val_mse: 0.9970\n",
      "Epoch 48/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9729 - mse: 0.9676 - val_loss: 0.9788 - val_mse: 0.9810\n",
      "Epoch 49/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9663 - mse: 0.9531 - val_loss: 0.9714 - val_mse: 0.9666\n",
      "Epoch 50/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9598 - mse: 0.9463 - val_loss: 0.9645 - val_mse: 0.9529\n",
      "Epoch 51/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.9526 - mse: 0.9278 - val_loss: 0.9575 - val_mse: 0.9393\n",
      "Epoch 52/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9469 - mse: 0.9189 - val_loss: 0.9509 - val_mse: 0.9265\n",
      "Epoch 53/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9401 - mse: 0.9053 - val_loss: 0.9443 - val_mse: 0.9138\n",
      "Epoch 54/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9320 - mse: 0.8911 - val_loss: 0.9377 - val_mse: 0.9011\n",
      "Epoch 55/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9254 - mse: 0.8822 - val_loss: 0.9311 - val_mse: 0.8886\n",
      "Epoch 56/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9229 - mse: 0.8724 - val_loss: 0.9249 - val_mse: 0.8770\n",
      "Epoch 57/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9139 - mse: 0.8580 - val_loss: 0.9192 - val_mse: 0.8663\n",
      "Epoch 58/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9104 - mse: 0.8496 - val_loss: 0.9135 - val_mse: 0.8556\n",
      "Epoch 59/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9020 - mse: 0.8340 - val_loss: 0.9077 - val_mse: 0.8449\n",
      "Epoch 60/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9038 - mse: 0.8328 - val_loss: 0.9020 - val_mse: 0.8343\n",
      "Epoch 61/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8915 - mse: 0.8170 - val_loss: 0.8970 - val_mse: 0.8251\n",
      "Epoch 62/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8904 - mse: 0.8130 - val_loss: 0.8918 - val_mse: 0.8157\n",
      "Epoch 63/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8830 - mse: 0.8011 - val_loss: 0.8863 - val_mse: 0.8058\n",
      "Epoch 64/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8777 - mse: 0.7892 - val_loss: 0.8815 - val_mse: 0.7971\n",
      "Epoch 65/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8766 - mse: 0.7871 - val_loss: 0.8763 - val_mse: 0.7877\n",
      "Epoch 66/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8711 - mse: 0.7784 - val_loss: 0.8715 - val_mse: 0.7791\n",
      "Epoch 67/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8644 - mse: 0.7655 - val_loss: 0.8668 - val_mse: 0.7707\n",
      "Epoch 68/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8628 - mse: 0.7647 - val_loss: 0.8623 - val_mse: 0.7628\n",
      "Epoch 69/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8588 - mse: 0.7586 - val_loss: 0.8583 - val_mse: 0.7558\n",
      "Epoch 70/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8490 - mse: 0.7417 - val_loss: 0.8541 - val_mse: 0.7485\n",
      "Epoch 71/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8517 - mse: 0.7451 - val_loss: 0.8503 - val_mse: 0.7418\n",
      "Epoch 72/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8443 - mse: 0.7334 - val_loss: 0.8461 - val_mse: 0.7346\n",
      "Epoch 73/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8464 - mse: 0.7341 - val_loss: 0.8422 - val_mse: 0.7278\n",
      "Epoch 74/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8386 - mse: 0.7210 - val_loss: 0.8380 - val_mse: 0.7205\n",
      "Epoch 75/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8345 - mse: 0.7154 - val_loss: 0.8345 - val_mse: 0.7146\n",
      "Epoch 76/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8325 - mse: 0.7135 - val_loss: 0.8304 - val_mse: 0.7075\n",
      "Epoch 77/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8294 - mse: 0.7073 - val_loss: 0.8270 - val_mse: 0.7017\n",
      "Epoch 78/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8257 - mse: 0.7016 - val_loss: 0.8234 - val_mse: 0.6954\n",
      "Epoch 79/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8207 - mse: 0.6931 - val_loss: 0.8201 - val_mse: 0.6899\n",
      "Epoch 80/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8202 - mse: 0.6908 - val_loss: 0.8170 - val_mse: 0.6846\n",
      "Epoch 81/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8160 - mse: 0.6844 - val_loss: 0.8134 - val_mse: 0.6786\n",
      "Epoch 82/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8125 - mse: 0.6755 - val_loss: 0.8104 - val_mse: 0.6737\n",
      "Epoch 83/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8109 - mse: 0.6766 - val_loss: 0.8071 - val_mse: 0.6681\n",
      "Epoch 84/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8080 - mse: 0.6706 - val_loss: 0.8042 - val_mse: 0.6633\n",
      "Epoch 85/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8048 - mse: 0.6640 - val_loss: 0.8010 - val_mse: 0.6579\n",
      "Epoch 86/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8027 - mse: 0.6589 - val_loss: 0.7980 - val_mse: 0.6529\n",
      "Epoch 87/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7962 - mse: 0.6519 - val_loss: 0.7950 - val_mse: 0.6481\n",
      "Epoch 88/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7967 - mse: 0.6527 - val_loss: 0.7921 - val_mse: 0.6432\n",
      "Epoch 89/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7935 - mse: 0.6474 - val_loss: 0.7900 - val_mse: 0.6397\n",
      "Epoch 90/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7917 - mse: 0.6432 - val_loss: 0.7872 - val_mse: 0.6351\n",
      "Epoch 91/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7928 - mse: 0.6457 - val_loss: 0.7843 - val_mse: 0.6304\n",
      "Epoch 92/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7853 - mse: 0.6329 - val_loss: 0.7820 - val_mse: 0.6267\n",
      "Epoch 93/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7828 - mse: 0.6304 - val_loss: 0.7794 - val_mse: 0.6225\n",
      "Epoch 94/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7850 - mse: 0.6301 - val_loss: 0.7765 - val_mse: 0.6177\n",
      "Epoch 95/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7820 - mse: 0.6272 - val_loss: 0.7739 - val_mse: 0.6135\n",
      "Epoch 96/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7755 - mse: 0.6175 - val_loss: 0.7721 - val_mse: 0.6105\n",
      "Epoch 97/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7748 - mse: 0.6138 - val_loss: 0.7695 - val_mse: 0.6064\n",
      "Epoch 98/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7739 - mse: 0.6141 - val_loss: 0.7674 - val_mse: 0.6031\n",
      "Epoch 99/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7749 - mse: 0.6138 - val_loss: 0.7650 - val_mse: 0.5993\n",
      "Epoch 100/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7683 - mse: 0.6039 - val_loss: 0.7629 - val_mse: 0.5959\n",
      "Epoch 101/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7676 - mse: 0.6026 - val_loss: 0.7605 - val_mse: 0.5920\n",
      "Epoch 102/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7642 - mse: 0.5998 - val_loss: 0.7583 - val_mse: 0.5884\n",
      "Epoch 103/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7625 - mse: 0.5972 - val_loss: 0.7558 - val_mse: 0.5845\n",
      "Epoch 104/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7614 - mse: 0.5931 - val_loss: 0.7537 - val_mse: 0.5813\n",
      "Epoch 105/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7604 - mse: 0.5939 - val_loss: 0.7517 - val_mse: 0.5781\n",
      "Epoch 106/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7584 - mse: 0.5907 - val_loss: 0.7494 - val_mse: 0.5745\n",
      "Epoch 107/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7585 - mse: 0.5885 - val_loss: 0.7475 - val_mse: 0.5715\n",
      "Epoch 108/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7530 - mse: 0.5799 - val_loss: 0.7455 - val_mse: 0.5682\n",
      "Epoch 109/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7531 - mse: 0.5801 - val_loss: 0.7438 - val_mse: 0.5657\n",
      "Epoch 110/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7478 - mse: 0.5735 - val_loss: 0.7416 - val_mse: 0.5622\n",
      "Epoch 111/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7479 - mse: 0.5730 - val_loss: 0.7394 - val_mse: 0.5588\n",
      "Epoch 112/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.7451 - mse: 0.5674 - val_loss: 0.7378 - val_mse: 0.5564\n",
      "Epoch 113/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7474 - mse: 0.5709 - val_loss: 0.7354 - val_mse: 0.5525\n",
      "Epoch 114/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7446 - mse: 0.5662 - val_loss: 0.7337 - val_mse: 0.5500\n",
      "Epoch 115/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7414 - mse: 0.5647 - val_loss: 0.7319 - val_mse: 0.5472\n",
      "Epoch 116/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7399 - mse: 0.5600 - val_loss: 0.7299 - val_mse: 0.5441\n",
      "Epoch 117/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.7372 - mse: 0.5567 - val_loss: 0.7282 - val_mse: 0.5415\n",
      "Epoch 118/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.7350 - mse: 0.5542 - val_loss: 0.7262 - val_mse: 0.5384\n",
      "Epoch 119/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7338 - mse: 0.5500 - val_loss: 0.7246 - val_mse: 0.5361\n",
      "Epoch 120/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7322 - mse: 0.5499 - val_loss: 0.7229 - val_mse: 0.5334\n",
      "Epoch 121/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7328 - mse: 0.5472 - val_loss: 0.7213 - val_mse: 0.5310\n",
      "Epoch 122/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7336 - mse: 0.5506 - val_loss: 0.7194 - val_mse: 0.5280\n",
      "Epoch 123/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7266 - mse: 0.5398 - val_loss: 0.7180 - val_mse: 0.5261\n",
      "Epoch 124/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7272 - mse: 0.5406 - val_loss: 0.7165 - val_mse: 0.5238\n",
      "Epoch 125/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7262 - mse: 0.5398 - val_loss: 0.7148 - val_mse: 0.5211\n",
      "Epoch 126/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7256 - mse: 0.5366 - val_loss: 0.7134 - val_mse: 0.5191\n",
      "Epoch 127/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7226 - mse: 0.5337 - val_loss: 0.7113 - val_mse: 0.5159\n",
      "Epoch 128/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7251 - mse: 0.5370 - val_loss: 0.7102 - val_mse: 0.5143\n",
      "Epoch 129/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7200 - mse: 0.5285 - val_loss: 0.7084 - val_mse: 0.5117\n",
      "Epoch 130/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7197 - mse: 0.5285 - val_loss: 0.7067 - val_mse: 0.5091\n",
      "Epoch 131/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7135 - mse: 0.5201 - val_loss: 0.7052 - val_mse: 0.5070\n",
      "Epoch 132/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7168 - mse: 0.5234 - val_loss: 0.7040 - val_mse: 0.5052\n",
      "Epoch 133/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7107 - mse: 0.5145 - val_loss: 0.7024 - val_mse: 0.5028\n",
      "Epoch 134/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7144 - mse: 0.5220 - val_loss: 0.7008 - val_mse: 0.5005\n",
      "Epoch 135/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7100 - mse: 0.5150 - val_loss: 0.6993 - val_mse: 0.4983\n",
      "Epoch 136/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7112 - mse: 0.5169 - val_loss: 0.6980 - val_mse: 0.4963\n",
      "Epoch 137/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7088 - mse: 0.5134 - val_loss: 0.6967 - val_mse: 0.4944\n",
      "Epoch 138/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7062 - mse: 0.5097 - val_loss: 0.6957 - val_mse: 0.4931\n",
      "Epoch 139/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7084 - mse: 0.5121 - val_loss: 0.6943 - val_mse: 0.4909\n",
      "Epoch 140/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7065 - mse: 0.5086 - val_loss: 0.6925 - val_mse: 0.4883\n",
      "Epoch 141/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7047 - mse: 0.5065 - val_loss: 0.6912 - val_mse: 0.4865\n",
      "Epoch 142/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7023 - mse: 0.5034 - val_loss: 0.6902 - val_mse: 0.4850\n",
      "Epoch 143/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7031 - mse: 0.5040 - val_loss: 0.6889 - val_mse: 0.4831\n",
      "Epoch 144/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6972 - mse: 0.4962 - val_loss: 0.6878 - val_mse: 0.4816\n",
      "Epoch 145/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6983 - mse: 0.4973 - val_loss: 0.6864 - val_mse: 0.4796\n",
      "Epoch 146/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6962 - mse: 0.4937 - val_loss: 0.6850 - val_mse: 0.4775\n",
      "Epoch 147/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6969 - mse: 0.4951 - val_loss: 0.6835 - val_mse: 0.4754\n",
      "Epoch 148/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6954 - mse: 0.4943 - val_loss: 0.6826 - val_mse: 0.4741\n",
      "Epoch 149/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6947 - mse: 0.4928 - val_loss: 0.6811 - val_mse: 0.4720\n",
      "Epoch 150/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6911 - mse: 0.4871 - val_loss: 0.6803 - val_mse: 0.4710\n",
      "Epoch 151/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6890 - mse: 0.4858 - val_loss: 0.6788 - val_mse: 0.4689\n",
      "Epoch 152/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6884 - mse: 0.4827 - val_loss: 0.6776 - val_mse: 0.4671\n",
      "Epoch 153/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6881 - mse: 0.4825 - val_loss: 0.6764 - val_mse: 0.4654\n",
      "Epoch 154/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6873 - mse: 0.4809 - val_loss: 0.6757 - val_mse: 0.4644\n",
      "Epoch 155/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6855 - mse: 0.4801 - val_loss: 0.6744 - val_mse: 0.4626\n",
      "Epoch 156/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6875 - mse: 0.4814 - val_loss: 0.6732 - val_mse: 0.4610\n",
      "Epoch 157/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6838 - mse: 0.4780 - val_loss: 0.6720 - val_mse: 0.4592\n",
      "Epoch 158/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6853 - mse: 0.4788 - val_loss: 0.6711 - val_mse: 0.4580\n",
      "Epoch 159/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6827 - mse: 0.4752 - val_loss: 0.6701 - val_mse: 0.4566\n",
      "Epoch 160/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6843 - mse: 0.4768 - val_loss: 0.6690 - val_mse: 0.4551\n",
      "Epoch 161/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6813 - mse: 0.4732 - val_loss: 0.6683 - val_mse: 0.4542\n",
      "Epoch 162/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6788 - mse: 0.4693 - val_loss: 0.6671 - val_mse: 0.4525\n",
      "Epoch 163/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6782 - mse: 0.4694 - val_loss: 0.6662 - val_mse: 0.4513\n",
      "Epoch 164/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6762 - mse: 0.4653 - val_loss: 0.6651 - val_mse: 0.4498\n",
      "Epoch 165/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6747 - mse: 0.4658 - val_loss: 0.6642 - val_mse: 0.4486\n",
      "Epoch 166/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6768 - mse: 0.4671 - val_loss: 0.6632 - val_mse: 0.4471\n",
      "Epoch 167/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6758 - mse: 0.4650 - val_loss: 0.6627 - val_mse: 0.4465\n",
      "Epoch 168/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6742 - mse: 0.4617 - val_loss: 0.6615 - val_mse: 0.4448\n",
      "Epoch 169/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6734 - mse: 0.4629 - val_loss: 0.6607 - val_mse: 0.4438\n",
      "Epoch 170/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6736 - mse: 0.4628 - val_loss: 0.6600 - val_mse: 0.4428\n",
      "Epoch 171/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6716 - mse: 0.4596 - val_loss: 0.6590 - val_mse: 0.4415\n",
      "Epoch 172/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6710 - mse: 0.4586 - val_loss: 0.6582 - val_mse: 0.4404\n",
      "Epoch 173/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6695 - mse: 0.4566 - val_loss: 0.6577 - val_mse: 0.4398\n",
      "Epoch 174/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6684 - mse: 0.4541 - val_loss: 0.6569 - val_mse: 0.4386\n",
      "Epoch 175/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6670 - mse: 0.4541 - val_loss: 0.6561 - val_mse: 0.4376\n",
      "Epoch 176/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6660 - mse: 0.4521 - val_loss: 0.6552 - val_mse: 0.4363\n",
      "Epoch 177/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6658 - mse: 0.4524 - val_loss: 0.6545 - val_mse: 0.4354\n",
      "Epoch 178/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6653 - mse: 0.4511 - val_loss: 0.6538 - val_mse: 0.4344\n",
      "Epoch 179/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6678 - mse: 0.4540 - val_loss: 0.6529 - val_mse: 0.4333\n",
      "Epoch 180/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6601 - mse: 0.4436 - val_loss: 0.6522 - val_mse: 0.4323\n",
      "Epoch 181/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6619 - mse: 0.4469 - val_loss: 0.6515 - val_mse: 0.4314\n",
      "Epoch 182/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6620 - mse: 0.4468 - val_loss: 0.6509 - val_mse: 0.4307\n",
      "Epoch 183/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6606 - mse: 0.4450 - val_loss: 0.6505 - val_mse: 0.4301\n",
      "Epoch 184/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6624 - mse: 0.4472 - val_loss: 0.6497 - val_mse: 0.4291\n",
      "Epoch 185/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6616 - mse: 0.4463 - val_loss: 0.6492 - val_mse: 0.4284\n",
      "Epoch 186/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6595 - mse: 0.4430 - val_loss: 0.6488 - val_mse: 0.4278\n",
      "Epoch 187/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6581 - mse: 0.4415 - val_loss: 0.6477 - val_mse: 0.4263\n",
      "Epoch 188/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6590 - mse: 0.4429 - val_loss: 0.6474 - val_mse: 0.4260\n",
      "Epoch 189/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6553 - mse: 0.4377 - val_loss: 0.6470 - val_mse: 0.4254\n",
      "Epoch 190/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6588 - mse: 0.4422 - val_loss: 0.6464 - val_mse: 0.4246\n",
      "Epoch 191/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6584 - mse: 0.4410 - val_loss: 0.6458 - val_mse: 0.4239\n",
      "Epoch 192/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6577 - mse: 0.4410 - val_loss: 0.6452 - val_mse: 0.4231\n",
      "Epoch 193/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6566 - mse: 0.4389 - val_loss: 0.6447 - val_mse: 0.4224\n",
      "Epoch 194/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.6571 - mse: 0.4401 - val_loss: 0.6441 - val_mse: 0.4217\n",
      "Epoch 195/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6538 - mse: 0.4364 - val_loss: 0.6437 - val_mse: 0.4211\n",
      "Epoch 196/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6551 - mse: 0.4359 - val_loss: 0.6428 - val_mse: 0.4199\n",
      "Epoch 197/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6519 - mse: 0.4330 - val_loss: 0.6424 - val_mse: 0.4195\n",
      "Epoch 198/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6519 - mse: 0.4331 - val_loss: 0.6420 - val_mse: 0.4190\n",
      "Epoch 199/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6519 - mse: 0.4332 - val_loss: 0.6415 - val_mse: 0.4183\n",
      "Epoch 200/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6511 - mse: 0.4312 - val_loss: 0.6411 - val_mse: 0.4177\n",
      "Epoch 201/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6522 - mse: 0.4337 - val_loss: 0.6408 - val_mse: 0.4174\n",
      "Epoch 202/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6489 - mse: 0.4293 - val_loss: 0.6405 - val_mse: 0.4170\n",
      "Epoch 203/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6511 - mse: 0.4319 - val_loss: 0.6397 - val_mse: 0.4159\n",
      "Epoch 204/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6482 - mse: 0.4276 - val_loss: 0.6395 - val_mse: 0.4157\n",
      "Epoch 205/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6496 - mse: 0.4296 - val_loss: 0.6391 - val_mse: 0.4151\n",
      "Epoch 206/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6509 - mse: 0.4323 - val_loss: 0.6384 - val_mse: 0.4143\n",
      "Epoch 207/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6507 - mse: 0.4306 - val_loss: 0.6377 - val_mse: 0.4133\n",
      "Epoch 208/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6458 - mse: 0.4248 - val_loss: 0.6375 - val_mse: 0.4131\n",
      "Epoch 209/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6485 - mse: 0.4287 - val_loss: 0.6373 - val_mse: 0.4129\n",
      "Epoch 210/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6482 - mse: 0.4290 - val_loss: 0.6368 - val_mse: 0.4122\n",
      "Epoch 211/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6439 - mse: 0.4224 - val_loss: 0.6364 - val_mse: 0.4117\n",
      "Epoch 212/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6448 - mse: 0.4235 - val_loss: 0.6363 - val_mse: 0.4116\n",
      "Epoch 213/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6427 - mse: 0.4214 - val_loss: 0.6356 - val_mse: 0.4107\n",
      "Epoch 214/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6435 - mse: 0.4218 - val_loss: 0.6353 - val_mse: 0.4102\n",
      "Epoch 215/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6432 - mse: 0.4219 - val_loss: 0.6347 - val_mse: 0.4095\n",
      "Epoch 216/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6432 - mse: 0.4213 - val_loss: 0.6344 - val_mse: 0.4091\n",
      "Epoch 217/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6421 - mse: 0.4196 - val_loss: 0.6341 - val_mse: 0.4088\n",
      "Epoch 218/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6434 - mse: 0.4219 - val_loss: 0.6338 - val_mse: 0.4084\n",
      "Epoch 219/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6432 - mse: 0.4213 - val_loss: 0.6333 - val_mse: 0.4077\n",
      "Epoch 220/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6433 - mse: 0.4220 - val_loss: 0.6331 - val_mse: 0.4075\n",
      "Epoch 221/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6411 - mse: 0.4188 - val_loss: 0.6328 - val_mse: 0.4070\n",
      "Epoch 222/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6381 - mse: 0.4155 - val_loss: 0.6325 - val_mse: 0.4067\n",
      "Epoch 223/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6383 - mse: 0.4153 - val_loss: 0.6325 - val_mse: 0.4067\n",
      "Epoch 224/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6386 - mse: 0.4155 - val_loss: 0.6321 - val_mse: 0.4062\n",
      "Epoch 225/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6402 - mse: 0.4183 - val_loss: 0.6316 - val_mse: 0.4055\n",
      "Epoch 226/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6415 - mse: 0.4186 - val_loss: 0.6309 - val_mse: 0.4047\n",
      "Epoch 227/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6401 - mse: 0.4172 - val_loss: 0.6306 - val_mse: 0.4042\n",
      "Epoch 228/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6361 - mse: 0.4125 - val_loss: 0.6307 - val_mse: 0.4044\n",
      "Epoch 229/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6373 - mse: 0.4139 - val_loss: 0.6302 - val_mse: 0.4037\n",
      "Epoch 230/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.6371 - mse: 0.4136 - val_loss: 0.6298 - val_mse: 0.4032\n",
      "Epoch 231/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6395 - mse: 0.4160 - val_loss: 0.6300 - val_mse: 0.4035\n",
      "Epoch 232/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6347 - mse: 0.4104 - val_loss: 0.6292 - val_mse: 0.4025\n",
      "Epoch 233/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6371 - mse: 0.4137 - val_loss: 0.6292 - val_mse: 0.4025\n",
      "Epoch 234/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6367 - mse: 0.4132 - val_loss: 0.6289 - val_mse: 0.4022\n",
      "Epoch 235/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6346 - mse: 0.4095 - val_loss: 0.6283 - val_mse: 0.4014\n",
      "Epoch 236/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6364 - mse: 0.4126 - val_loss: 0.6279 - val_mse: 0.4008\n",
      "Epoch 237/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6374 - mse: 0.4135 - val_loss: 0.6279 - val_mse: 0.4009\n",
      "Epoch 238/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6349 - mse: 0.4109 - val_loss: 0.6279 - val_mse: 0.4009\n",
      "Epoch 239/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6328 - mse: 0.4086 - val_loss: 0.6273 - val_mse: 0.4001\n",
      "Epoch 240/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6314 - mse: 0.4058 - val_loss: 0.6271 - val_mse: 0.3999\n",
      "Epoch 241/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6327 - mse: 0.4078 - val_loss: 0.6267 - val_mse: 0.3994\n",
      "Epoch 242/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6313 - mse: 0.4062 - val_loss: 0.6266 - val_mse: 0.3992\n",
      "Epoch 243/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6336 - mse: 0.4084 - val_loss: 0.6262 - val_mse: 0.3987\n",
      "Epoch 244/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6304 - mse: 0.4051 - val_loss: 0.6260 - val_mse: 0.3984\n",
      "Epoch 245/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6316 - mse: 0.4063 - val_loss: 0.6254 - val_mse: 0.3977\n",
      "Epoch 246/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6304 - mse: 0.4048 - val_loss: 0.6252 - val_mse: 0.3974\n",
      "Epoch 247/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6300 - mse: 0.4045 - val_loss: 0.6250 - val_mse: 0.3972\n",
      "Epoch 248/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6304 - mse: 0.4045 - val_loss: 0.6247 - val_mse: 0.3968\n",
      "Epoch 249/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6328 - mse: 0.4079 - val_loss: 0.6246 - val_mse: 0.3967\n",
      "Epoch 250/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6296 - mse: 0.4038 - val_loss: 0.6243 - val_mse: 0.3964\n",
      "Epoch 251/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6307 - mse: 0.4047 - val_loss: 0.6242 - val_mse: 0.3961\n",
      "Epoch 252/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6263 - mse: 0.4003 - val_loss: 0.6237 - val_mse: 0.3956\n",
      "Epoch 253/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6308 - mse: 0.4053 - val_loss: 0.6239 - val_mse: 0.3958\n",
      "Epoch 254/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6283 - mse: 0.4025 - val_loss: 0.6236 - val_mse: 0.3954\n",
      "Epoch 255/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6264 - mse: 0.4001 - val_loss: 0.6230 - val_mse: 0.3946\n",
      "Epoch 256/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6270 - mse: 0.4006 - val_loss: 0.6229 - val_mse: 0.3945\n",
      "Epoch 257/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6271 - mse: 0.4012 - val_loss: 0.6226 - val_mse: 0.3941\n",
      "Epoch 258/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6254 - mse: 0.3985 - val_loss: 0.6225 - val_mse: 0.3941\n",
      "Epoch 259/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6265 - mse: 0.3997 - val_loss: 0.6223 - val_mse: 0.3938\n",
      "Epoch 260/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6285 - mse: 0.4030 - val_loss: 0.6220 - val_mse: 0.3934\n",
      "Epoch 261/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6244 - mse: 0.3981 - val_loss: 0.6218 - val_mse: 0.3932\n",
      "Epoch 262/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6239 - mse: 0.3965 - val_loss: 0.6211 - val_mse: 0.3922\n",
      "Epoch 263/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6234 - mse: 0.3962 - val_loss: 0.6210 - val_mse: 0.3921\n",
      "Epoch 264/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6275 - mse: 0.4016 - val_loss: 0.6211 - val_mse: 0.3923\n",
      "Epoch 265/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6262 - mse: 0.3995 - val_loss: 0.6209 - val_mse: 0.3920\n",
      "Epoch 266/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6250 - mse: 0.3984 - val_loss: 0.6204 - val_mse: 0.3914\n",
      "Epoch 267/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6230 - mse: 0.3952 - val_loss: 0.6201 - val_mse: 0.3910\n",
      "Epoch 268/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6235 - mse: 0.3961 - val_loss: 0.6200 - val_mse: 0.3910\n",
      "Epoch 269/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6234 - mse: 0.3967 - val_loss: 0.6202 - val_mse: 0.3911\n",
      "Epoch 270/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6229 - mse: 0.3952 - val_loss: 0.6196 - val_mse: 0.3904\n",
      "Epoch 271/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6212 - mse: 0.3936 - val_loss: 0.6192 - val_mse: 0.3899\n",
      "Epoch 272/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6223 - mse: 0.3942 - val_loss: 0.6191 - val_mse: 0.3898\n",
      "Epoch 273/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6223 - mse: 0.3948 - val_loss: 0.6188 - val_mse: 0.3894\n",
      "Epoch 274/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6215 - mse: 0.3933 - val_loss: 0.6182 - val_mse: 0.3887\n",
      "Epoch 275/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6225 - mse: 0.3950 - val_loss: 0.6180 - val_mse: 0.3884\n",
      "Epoch 276/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6191 - mse: 0.3910 - val_loss: 0.6182 - val_mse: 0.3887\n",
      "Epoch 277/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6175 - mse: 0.3886 - val_loss: 0.6178 - val_mse: 0.3882\n",
      "Epoch 278/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6234 - mse: 0.3962 - val_loss: 0.6174 - val_mse: 0.3877\n",
      "Epoch 279/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6181 - mse: 0.3889 - val_loss: 0.6175 - val_mse: 0.3878\n",
      "Epoch 280/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6217 - mse: 0.3932 - val_loss: 0.6175 - val_mse: 0.3878\n",
      "Epoch 281/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6192 - mse: 0.3916 - val_loss: 0.6167 - val_mse: 0.3868\n",
      "Epoch 282/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6169 - mse: 0.3880 - val_loss: 0.6167 - val_mse: 0.3868\n",
      "Epoch 283/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6194 - mse: 0.3913 - val_loss: 0.6167 - val_mse: 0.3868\n",
      "Epoch 284/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6147 - mse: 0.3864 - val_loss: 0.6161 - val_mse: 0.3860\n",
      "Epoch 285/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6178 - mse: 0.3894 - val_loss: 0.6155 - val_mse: 0.3853\n",
      "Epoch 286/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6177 - mse: 0.3889 - val_loss: 0.6155 - val_mse: 0.3853\n",
      "Epoch 287/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6186 - mse: 0.3901 - val_loss: 0.6154 - val_mse: 0.3851\n",
      "Epoch 288/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6189 - mse: 0.3904 - val_loss: 0.6154 - val_mse: 0.3852\n",
      "Epoch 289/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6167 - mse: 0.3877 - val_loss: 0.6148 - val_mse: 0.3844\n",
      "Epoch 290/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6156 - mse: 0.3865 - val_loss: 0.6148 - val_mse: 0.3845\n",
      "Epoch 291/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6159 - mse: 0.3867 - val_loss: 0.6147 - val_mse: 0.3844\n",
      "Epoch 292/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6157 - mse: 0.3866 - val_loss: 0.6145 - val_mse: 0.3841\n",
      "Epoch 293/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6148 - mse: 0.3853 - val_loss: 0.6141 - val_mse: 0.3835\n",
      "Epoch 294/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6180 - mse: 0.3881 - val_loss: 0.6139 - val_mse: 0.3833\n",
      "Epoch 295/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6134 - mse: 0.3831 - val_loss: 0.6138 - val_mse: 0.3832\n",
      "Epoch 296/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6146 - mse: 0.3848 - val_loss: 0.6133 - val_mse: 0.3826\n",
      "Epoch 297/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6122 - mse: 0.3818 - val_loss: 0.6134 - val_mse: 0.3827\n",
      "Epoch 298/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6157 - mse: 0.3865 - val_loss: 0.6131 - val_mse: 0.3823\n",
      "Epoch 299/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6141 - mse: 0.3840 - val_loss: 0.6131 - val_mse: 0.3824\n",
      "Epoch 300/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6146 - mse: 0.3852 - val_loss: 0.6127 - val_mse: 0.3818\n",
      "Epoch 301/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6116 - mse: 0.3820 - val_loss: 0.6123 - val_mse: 0.3813\n",
      "Epoch 302/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6126 - mse: 0.3819 - val_loss: 0.6120 - val_mse: 0.3810\n",
      "Epoch 303/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6134 - mse: 0.3837 - val_loss: 0.6120 - val_mse: 0.3810\n",
      "Epoch 304/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6128 - mse: 0.3833 - val_loss: 0.6118 - val_mse: 0.3806\n",
      "Epoch 305/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6127 - mse: 0.3822 - val_loss: 0.6114 - val_mse: 0.3802\n",
      "Epoch 306/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6138 - mse: 0.3835 - val_loss: 0.6112 - val_mse: 0.3799\n",
      "Epoch 307/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6117 - mse: 0.3813 - val_loss: 0.6109 - val_mse: 0.3796\n",
      "Epoch 308/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6103 - mse: 0.3797 - val_loss: 0.6106 - val_mse: 0.3793\n",
      "Epoch 309/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6112 - mse: 0.3815 - val_loss: 0.6108 - val_mse: 0.3795\n",
      "Epoch 310/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6113 - mse: 0.3810 - val_loss: 0.6108 - val_mse: 0.3795\n",
      "Epoch 311/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6089 - mse: 0.3778 - val_loss: 0.6101 - val_mse: 0.3786\n",
      "Epoch 312/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6090 - mse: 0.3780 - val_loss: 0.6097 - val_mse: 0.3781\n",
      "Epoch 313/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6081 - mse: 0.3768 - val_loss: 0.6095 - val_mse: 0.3778\n",
      "Epoch 314/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6095 - mse: 0.3781 - val_loss: 0.6094 - val_mse: 0.3777\n",
      "Epoch 315/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6081 - mse: 0.3779 - val_loss: 0.6090 - val_mse: 0.3772\n",
      "Epoch 316/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6089 - mse: 0.3785 - val_loss: 0.6090 - val_mse: 0.3773\n",
      "Epoch 317/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6104 - mse: 0.3796 - val_loss: 0.6089 - val_mse: 0.3771\n",
      "Epoch 318/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6075 - mse: 0.3766 - val_loss: 0.6087 - val_mse: 0.3768\n",
      "Epoch 319/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6078 - mse: 0.3767 - val_loss: 0.6082 - val_mse: 0.3762\n",
      "Epoch 320/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6066 - mse: 0.3745 - val_loss: 0.6083 - val_mse: 0.3764\n",
      "Epoch 321/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6053 - mse: 0.3741 - val_loss: 0.6077 - val_mse: 0.3756\n",
      "Epoch 322/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6067 - mse: 0.3753 - val_loss: 0.6074 - val_mse: 0.3753\n",
      "Epoch 323/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6057 - mse: 0.3751 - val_loss: 0.6076 - val_mse: 0.3755\n",
      "Epoch 324/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6048 - mse: 0.3730 - val_loss: 0.6072 - val_mse: 0.3750\n",
      "Epoch 325/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6044 - mse: 0.3727 - val_loss: 0.6070 - val_mse: 0.3747\n",
      "Epoch 326/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6056 - mse: 0.3735 - val_loss: 0.6072 - val_mse: 0.3750\n",
      "Epoch 327/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6049 - mse: 0.3729 - val_loss: 0.6067 - val_mse: 0.3744\n",
      "Epoch 328/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6052 - mse: 0.3736 - val_loss: 0.6064 - val_mse: 0.3741\n",
      "Epoch 329/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6071 - mse: 0.3750 - val_loss: 0.6060 - val_mse: 0.3735\n",
      "Epoch 330/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6050 - mse: 0.3730 - val_loss: 0.6055 - val_mse: 0.3730\n",
      "Epoch 331/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6039 - mse: 0.3715 - val_loss: 0.6053 - val_mse: 0.3727\n",
      "Epoch 332/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6028 - mse: 0.3703 - val_loss: 0.6052 - val_mse: 0.3725\n",
      "Epoch 333/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6047 - mse: 0.3727 - val_loss: 0.6052 - val_mse: 0.3725\n",
      "Epoch 334/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6028 - mse: 0.3702 - val_loss: 0.6048 - val_mse: 0.3720\n",
      "Epoch 335/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6003 - mse: 0.3673 - val_loss: 0.6049 - val_mse: 0.3722\n",
      "Epoch 336/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6024 - mse: 0.3694 - val_loss: 0.6043 - val_mse: 0.3714\n",
      "Epoch 337/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6031 - mse: 0.3712 - val_loss: 0.6042 - val_mse: 0.3714\n",
      "Epoch 338/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6034 - mse: 0.3713 - val_loss: 0.6039 - val_mse: 0.3710\n",
      "Epoch 339/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6012 - mse: 0.3680 - val_loss: 0.6037 - val_mse: 0.3707\n",
      "Epoch 340/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6006 - mse: 0.3676 - val_loss: 0.6038 - val_mse: 0.3709\n",
      "Epoch 341/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6031 - mse: 0.3709 - val_loss: 0.6036 - val_mse: 0.3706\n",
      "Epoch 342/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6018 - mse: 0.3687 - val_loss: 0.6030 - val_mse: 0.3699\n",
      "Epoch 343/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6027 - mse: 0.3696 - val_loss: 0.6027 - val_mse: 0.3695\n",
      "Epoch 344/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6019 - mse: 0.3687 - val_loss: 0.6024 - val_mse: 0.3691\n",
      "Epoch 345/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5998 - mse: 0.3662 - val_loss: 0.6022 - val_mse: 0.3689\n",
      "Epoch 346/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6019 - mse: 0.3693 - val_loss: 0.6020 - val_mse: 0.3687\n",
      "Epoch 347/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5984 - mse: 0.3659 - val_loss: 0.6022 - val_mse: 0.3689\n",
      "Epoch 348/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5987 - mse: 0.3653 - val_loss: 0.6016 - val_mse: 0.3682\n",
      "Epoch 349/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5967 - mse: 0.3637 - val_loss: 0.6017 - val_mse: 0.3683\n",
      "Epoch 350/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5999 - mse: 0.3667 - val_loss: 0.6011 - val_mse: 0.3676\n",
      "Epoch 351/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5968 - mse: 0.3631 - val_loss: 0.6006 - val_mse: 0.3669\n",
      "Epoch 352/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6002 - mse: 0.3675 - val_loss: 0.6005 - val_mse: 0.3668\n",
      "Epoch 353/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5980 - mse: 0.3640 - val_loss: 0.6003 - val_mse: 0.3665\n",
      "Epoch 354/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5967 - mse: 0.3627 - val_loss: 0.6003 - val_mse: 0.3665\n",
      "Epoch 355/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5970 - mse: 0.3633 - val_loss: 0.5998 - val_mse: 0.3660\n",
      "Epoch 356/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5960 - mse: 0.3622 - val_loss: 0.6001 - val_mse: 0.3664\n",
      "Epoch 357/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5962 - mse: 0.3623 - val_loss: 0.5994 - val_mse: 0.3655\n",
      "Epoch 358/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5946 - mse: 0.3609 - val_loss: 0.5993 - val_mse: 0.3653\n",
      "Epoch 359/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5949 - mse: 0.3609 - val_loss: 0.5991 - val_mse: 0.3651\n",
      "Epoch 360/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5952 - mse: 0.3612 - val_loss: 0.5989 - val_mse: 0.3649\n",
      "Epoch 361/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5955 - mse: 0.3613 - val_loss: 0.5984 - val_mse: 0.3642\n",
      "Epoch 362/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5964 - mse: 0.3626 - val_loss: 0.5984 - val_mse: 0.3643\n",
      "Epoch 363/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5959 - mse: 0.3614 - val_loss: 0.5981 - val_mse: 0.3639\n",
      "Epoch 364/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5936 - mse: 0.3587 - val_loss: 0.5982 - val_mse: 0.3640\n",
      "Epoch 365/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5930 - mse: 0.3588 - val_loss: 0.5979 - val_mse: 0.3637\n",
      "Epoch 366/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5938 - mse: 0.3592 - val_loss: 0.5972 - val_mse: 0.3628\n",
      "Epoch 367/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5940 - mse: 0.3593 - val_loss: 0.5976 - val_mse: 0.3633\n",
      "Epoch 368/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5919 - mse: 0.3579 - val_loss: 0.5973 - val_mse: 0.3629\n",
      "Epoch 369/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5933 - mse: 0.3589 - val_loss: 0.5970 - val_mse: 0.3626\n",
      "Epoch 370/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5939 - mse: 0.3596 - val_loss: 0.5969 - val_mse: 0.3625\n",
      "Epoch 371/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5918 - mse: 0.3574 - val_loss: 0.5967 - val_mse: 0.3622\n",
      "Epoch 372/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5915 - mse: 0.3564 - val_loss: 0.5963 - val_mse: 0.3617\n",
      "Epoch 373/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5927 - mse: 0.3582 - val_loss: 0.5960 - val_mse: 0.3614\n",
      "Epoch 374/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5910 - mse: 0.3558 - val_loss: 0.5960 - val_mse: 0.3614\n",
      "Epoch 375/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5941 - mse: 0.3599 - val_loss: 0.5957 - val_mse: 0.3610\n",
      "Epoch 376/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5926 - mse: 0.3580 - val_loss: 0.5955 - val_mse: 0.3607\n",
      "Epoch 377/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5906 - mse: 0.3559 - val_loss: 0.5950 - val_mse: 0.3601\n",
      "Epoch 378/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5912 - mse: 0.3562 - val_loss: 0.5952 - val_mse: 0.3604\n",
      "Epoch 379/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5914 - mse: 0.3568 - val_loss: 0.5949 - val_mse: 0.3600\n",
      "Epoch 380/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5920 - mse: 0.3568 - val_loss: 0.5944 - val_mse: 0.3594\n",
      "Epoch 381/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5887 - mse: 0.3541 - val_loss: 0.5939 - val_mse: 0.3589\n",
      "Epoch 382/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5872 - mse: 0.3523 - val_loss: 0.5938 - val_mse: 0.3587\n",
      "Epoch 383/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5877 - mse: 0.3529 - val_loss: 0.5935 - val_mse: 0.3584\n",
      "Epoch 384/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5879 - mse: 0.3523 - val_loss: 0.5932 - val_mse: 0.3580\n",
      "Epoch 385/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5857 - mse: 0.3495 - val_loss: 0.5936 - val_mse: 0.3584\n",
      "Epoch 386/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5881 - mse: 0.3524 - val_loss: 0.5928 - val_mse: 0.3575\n",
      "Epoch 387/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5875 - mse: 0.3531 - val_loss: 0.5925 - val_mse: 0.3572\n",
      "Epoch 388/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5881 - mse: 0.3524 - val_loss: 0.5924 - val_mse: 0.3570\n",
      "Epoch 389/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5871 - mse: 0.3511 - val_loss: 0.5921 - val_mse: 0.3566\n",
      "Epoch 390/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5866 - mse: 0.3508 - val_loss: 0.5921 - val_mse: 0.3566\n",
      "Epoch 391/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5868 - mse: 0.3511 - val_loss: 0.5919 - val_mse: 0.3564\n",
      "Epoch 392/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5869 - mse: 0.3513 - val_loss: 0.5915 - val_mse: 0.3560\n",
      "Epoch 393/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5868 - mse: 0.3514 - val_loss: 0.5914 - val_mse: 0.3558\n",
      "Epoch 394/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5870 - mse: 0.3517 - val_loss: 0.5911 - val_mse: 0.3554\n",
      "Epoch 395/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5852 - mse: 0.3484 - val_loss: 0.5910 - val_mse: 0.3553\n",
      "Epoch 396/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5847 - mse: 0.3479 - val_loss: 0.5906 - val_mse: 0.3549\n",
      "Epoch 397/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5850 - mse: 0.3491 - val_loss: 0.5903 - val_mse: 0.3545\n",
      "Epoch 398/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5843 - mse: 0.3481 - val_loss: 0.5903 - val_mse: 0.3545\n",
      "Epoch 399/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5848 - mse: 0.3482 - val_loss: 0.5901 - val_mse: 0.3542\n",
      "Epoch 400/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5835 - mse: 0.3470 - val_loss: 0.5896 - val_mse: 0.3537\n",
      "Epoch 401/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5834 - mse: 0.3472 - val_loss: 0.5893 - val_mse: 0.3533\n",
      "Epoch 402/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5818 - mse: 0.3448 - val_loss: 0.5891 - val_mse: 0.3531\n",
      "Epoch 403/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5823 - mse: 0.3458 - val_loss: 0.5888 - val_mse: 0.3527\n",
      "Epoch 404/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5807 - mse: 0.3440 - val_loss: 0.5888 - val_mse: 0.3527\n",
      "Epoch 405/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5815 - mse: 0.3450 - val_loss: 0.5884 - val_mse: 0.3523\n",
      "Epoch 406/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5818 - mse: 0.3447 - val_loss: 0.5882 - val_mse: 0.3520\n",
      "Epoch 407/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5826 - mse: 0.3457 - val_loss: 0.5884 - val_mse: 0.3522\n",
      "Epoch 408/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5798 - mse: 0.3433 - val_loss: 0.5885 - val_mse: 0.3523\n",
      "Epoch 409/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5798 - mse: 0.3423 - val_loss: 0.5878 - val_mse: 0.3515\n",
      "Epoch 410/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5805 - mse: 0.3434 - val_loss: 0.5871 - val_mse: 0.3506\n",
      "Epoch 411/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5801 - mse: 0.3433 - val_loss: 0.5871 - val_mse: 0.3506\n",
      "Epoch 412/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5812 - mse: 0.3441 - val_loss: 0.5867 - val_mse: 0.3501\n",
      "Epoch 413/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5795 - mse: 0.3424 - val_loss: 0.5864 - val_mse: 0.3499\n",
      "Epoch 414/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5798 - mse: 0.3427 - val_loss: 0.5863 - val_mse: 0.3497\n",
      "Epoch 415/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5797 - mse: 0.3419 - val_loss: 0.5862 - val_mse: 0.3496\n",
      "Epoch 416/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5802 - mse: 0.3436 - val_loss: 0.5862 - val_mse: 0.3496\n",
      "Epoch 417/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5784 - mse: 0.3407 - val_loss: 0.5858 - val_mse: 0.3492\n",
      "Epoch 418/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5771 - mse: 0.3395 - val_loss: 0.5853 - val_mse: 0.3485\n",
      "Epoch 419/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5793 - mse: 0.3432 - val_loss: 0.5855 - val_mse: 0.3487\n",
      "Epoch 420/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5783 - mse: 0.3414 - val_loss: 0.5854 - val_mse: 0.3487\n",
      "Epoch 421/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5787 - mse: 0.3411 - val_loss: 0.5851 - val_mse: 0.3483\n",
      "Epoch 422/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5769 - mse: 0.3392 - val_loss: 0.5848 - val_mse: 0.3479\n",
      "Epoch 423/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5769 - mse: 0.3396 - val_loss: 0.5843 - val_mse: 0.3473\n",
      "Epoch 424/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5768 - mse: 0.3396 - val_loss: 0.5842 - val_mse: 0.3472\n",
      "Epoch 425/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5770 - mse: 0.3395 - val_loss: 0.5841 - val_mse: 0.3471\n",
      "Epoch 426/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5779 - mse: 0.3403 - val_loss: 0.5836 - val_mse: 0.3465\n",
      "Epoch 427/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5751 - mse: 0.3371 - val_loss: 0.5834 - val_mse: 0.3463\n",
      "Epoch 428/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5750 - mse: 0.3371 - val_loss: 0.5832 - val_mse: 0.3461\n",
      "Epoch 429/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5770 - mse: 0.3389 - val_loss: 0.5831 - val_mse: 0.3459\n",
      "Epoch 430/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5774 - mse: 0.3398 - val_loss: 0.5829 - val_mse: 0.3457\n",
      "Epoch 431/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5766 - mse: 0.3389 - val_loss: 0.5829 - val_mse: 0.3457\n",
      "Epoch 432/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5743 - mse: 0.3365 - val_loss: 0.5827 - val_mse: 0.3454\n",
      "Epoch 433/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5748 - mse: 0.3377 - val_loss: 0.5825 - val_mse: 0.3452\n",
      "Epoch 434/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5756 - mse: 0.3375 - val_loss: 0.5818 - val_mse: 0.3444\n",
      "Epoch 435/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5735 - mse: 0.3355 - val_loss: 0.5823 - val_mse: 0.3449\n",
      "Epoch 436/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5722 - mse: 0.3342 - val_loss: 0.5819 - val_mse: 0.3445\n",
      "Epoch 437/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5739 - mse: 0.3355 - val_loss: 0.5814 - val_mse: 0.3439\n",
      "Epoch 438/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5742 - mse: 0.3364 - val_loss: 0.5812 - val_mse: 0.3437\n",
      "Epoch 439/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5719 - mse: 0.3335 - val_loss: 0.5809 - val_mse: 0.3433\n",
      "Epoch 440/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5720 - mse: 0.3337 - val_loss: 0.5811 - val_mse: 0.3435\n",
      "Epoch 441/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5730 - mse: 0.3352 - val_loss: 0.5806 - val_mse: 0.3429\n",
      "Epoch 442/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5722 - mse: 0.3344 - val_loss: 0.5806 - val_mse: 0.3429\n",
      "Epoch 443/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5705 - mse: 0.3317 - val_loss: 0.5804 - val_mse: 0.3427\n",
      "Epoch 444/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5705 - mse: 0.3319 - val_loss: 0.5802 - val_mse: 0.3424\n",
      "Epoch 445/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5711 - mse: 0.3328 - val_loss: 0.5796 - val_mse: 0.3418\n",
      "Epoch 446/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5706 - mse: 0.3322 - val_loss: 0.5797 - val_mse: 0.3418\n",
      "Epoch 447/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5713 - mse: 0.3324 - val_loss: 0.5793 - val_mse: 0.3414\n",
      "Epoch 448/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5692 - mse: 0.3303 - val_loss: 0.5789 - val_mse: 0.3410\n",
      "Epoch 449/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5688 - mse: 0.3309 - val_loss: 0.5790 - val_mse: 0.3410\n",
      "Epoch 450/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5691 - mse: 0.3298 - val_loss: 0.5785 - val_mse: 0.3404\n",
      "Epoch 451/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5689 - mse: 0.3300 - val_loss: 0.5782 - val_mse: 0.3401\n",
      "Epoch 452/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5694 - mse: 0.3302 - val_loss: 0.5781 - val_mse: 0.3400\n",
      "Epoch 453/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5675 - mse: 0.3288 - val_loss: 0.5781 - val_mse: 0.3400\n",
      "Epoch 454/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5694 - mse: 0.3306 - val_loss: 0.5779 - val_mse: 0.3397\n",
      "Epoch 455/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5680 - mse: 0.3286 - val_loss: 0.5773 - val_mse: 0.3390\n",
      "Epoch 456/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5702 - mse: 0.3320 - val_loss: 0.5773 - val_mse: 0.3390\n",
      "Epoch 457/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5678 - mse: 0.3288 - val_loss: 0.5770 - val_mse: 0.3387\n",
      "Epoch 458/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5657 - mse: 0.3266 - val_loss: 0.5769 - val_mse: 0.3386\n",
      "Epoch 459/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5688 - mse: 0.3300 - val_loss: 0.5770 - val_mse: 0.3387\n",
      "Epoch 460/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5670 - mse: 0.3276 - val_loss: 0.5766 - val_mse: 0.3382\n",
      "Epoch 461/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5670 - mse: 0.3281 - val_loss: 0.5761 - val_mse: 0.3376\n",
      "Epoch 462/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5652 - mse: 0.3258 - val_loss: 0.5758 - val_mse: 0.3373\n",
      "Epoch 463/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5666 - mse: 0.3272 - val_loss: 0.5756 - val_mse: 0.3370\n",
      "Epoch 464/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5677 - mse: 0.3290 - val_loss: 0.5757 - val_mse: 0.3372\n",
      "Epoch 465/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5658 - mse: 0.3260 - val_loss: 0.5754 - val_mse: 0.3368\n",
      "Epoch 466/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5654 - mse: 0.3259 - val_loss: 0.5754 - val_mse: 0.3368\n",
      "Epoch 467/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5650 - mse: 0.3254 - val_loss: 0.5748 - val_mse: 0.3361\n",
      "Epoch 468/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5657 - mse: 0.3258 - val_loss: 0.5749 - val_mse: 0.3362\n",
      "Epoch 469/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5650 - mse: 0.3252 - val_loss: 0.5744 - val_mse: 0.3357\n",
      "Epoch 470/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5651 - mse: 0.3259 - val_loss: 0.5743 - val_mse: 0.3355\n",
      "Epoch 471/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5630 - mse: 0.3234 - val_loss: 0.5743 - val_mse: 0.3355\n",
      "Epoch 472/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5644 - mse: 0.3250 - val_loss: 0.5741 - val_mse: 0.3353\n",
      "Epoch 473/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5634 - mse: 0.3237 - val_loss: 0.5740 - val_mse: 0.3351\n",
      "Epoch 474/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5621 - mse: 0.3224 - val_loss: 0.5737 - val_mse: 0.3349\n",
      "Epoch 475/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5632 - mse: 0.3235 - val_loss: 0.5734 - val_mse: 0.3345\n",
      "Epoch 476/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5612 - mse: 0.3215 - val_loss: 0.5731 - val_mse: 0.3341\n",
      "Epoch 477/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5635 - mse: 0.3234 - val_loss: 0.5729 - val_mse: 0.3339\n",
      "Epoch 478/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5618 - mse: 0.3219 - val_loss: 0.5727 - val_mse: 0.3337\n",
      "Epoch 479/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5616 - mse: 0.3213 - val_loss: 0.5726 - val_mse: 0.3336\n",
      "Epoch 480/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5612 - mse: 0.3209 - val_loss: 0.5724 - val_mse: 0.3332\n",
      "Epoch 481/1000\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5627 - mse: 0.3229 - val_loss: 0.5722 - val_mse: 0.3330\n",
      "Epoch 482/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5610 - mse: 0.3214 - val_loss: 0.5723 - val_mse: 0.3332\n",
      "Epoch 483/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5595 - mse: 0.3193 - val_loss: 0.5721 - val_mse: 0.3330\n",
      "Epoch 484/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5597 - mse: 0.3198 - val_loss: 0.5718 - val_mse: 0.3326\n",
      "Epoch 485/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5620 - mse: 0.3217 - val_loss: 0.5716 - val_mse: 0.3323\n",
      "Epoch 486/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5608 - mse: 0.3210 - val_loss: 0.5715 - val_mse: 0.3322\n",
      "Epoch 487/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5616 - mse: 0.3218 - val_loss: 0.5713 - val_mse: 0.3320\n",
      "Epoch 488/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5620 - mse: 0.3218 - val_loss: 0.5710 - val_mse: 0.3316\n",
      "Epoch 489/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5590 - mse: 0.3188 - val_loss: 0.5706 - val_mse: 0.3312\n",
      "Epoch 490/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5583 - mse: 0.3179 - val_loss: 0.5706 - val_mse: 0.3313\n",
      "Epoch 491/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5583 - mse: 0.3176 - val_loss: 0.5702 - val_mse: 0.3308\n",
      "Epoch 492/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5582 - mse: 0.3177 - val_loss: 0.5703 - val_mse: 0.3309\n",
      "Epoch 493/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5579 - mse: 0.3182 - val_loss: 0.5702 - val_mse: 0.3307\n",
      "Epoch 494/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5604 - mse: 0.3201 - val_loss: 0.5698 - val_mse: 0.3303\n",
      "Epoch 495/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5556 - mse: 0.3150 - val_loss: 0.5696 - val_mse: 0.3300\n",
      "Epoch 496/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5592 - mse: 0.3187 - val_loss: 0.5694 - val_mse: 0.3298\n",
      "Epoch 497/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5574 - mse: 0.3164 - val_loss: 0.5692 - val_mse: 0.3295\n",
      "Epoch 498/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5601 - mse: 0.3194 - val_loss: 0.5690 - val_mse: 0.3293\n",
      "Epoch 499/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5585 - mse: 0.3177 - val_loss: 0.5693 - val_mse: 0.3296\n",
      "Epoch 500/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5560 - mse: 0.3155 - val_loss: 0.5691 - val_mse: 0.3294\n",
      "Epoch 501/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5566 - mse: 0.3165 - val_loss: 0.5688 - val_mse: 0.3291\n",
      "Epoch 502/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5561 - mse: 0.3157 - val_loss: 0.5683 - val_mse: 0.3286\n",
      "Epoch 503/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5547 - mse: 0.3140 - val_loss: 0.5681 - val_mse: 0.3283\n",
      "Epoch 504/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5579 - mse: 0.3174 - val_loss: 0.5679 - val_mse: 0.3280\n",
      "Epoch 505/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5533 - mse: 0.3123 - val_loss: 0.5677 - val_mse: 0.3278\n",
      "Epoch 506/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5560 - mse: 0.3148 - val_loss: 0.5676 - val_mse: 0.3277\n",
      "Epoch 507/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5553 - mse: 0.3149 - val_loss: 0.5674 - val_mse: 0.3275\n",
      "Epoch 508/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5550 - mse: 0.3143 - val_loss: 0.5670 - val_mse: 0.3271\n",
      "Epoch 509/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5551 - mse: 0.3143 - val_loss: 0.5668 - val_mse: 0.3267\n",
      "Epoch 510/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5563 - mse: 0.3154 - val_loss: 0.5672 - val_mse: 0.3272\n",
      "Epoch 511/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5516 - mse: 0.3107 - val_loss: 0.5668 - val_mse: 0.3267\n",
      "Epoch 512/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5538 - mse: 0.3125 - val_loss: 0.5662 - val_mse: 0.3261\n",
      "Epoch 513/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5526 - mse: 0.3110 - val_loss: 0.5663 - val_mse: 0.3262\n",
      "Epoch 514/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5529 - mse: 0.3119 - val_loss: 0.5661 - val_mse: 0.3259\n",
      "Epoch 515/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5544 - mse: 0.3134 - val_loss: 0.5662 - val_mse: 0.3261\n",
      "Epoch 516/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5528 - mse: 0.3114 - val_loss: 0.5659 - val_mse: 0.3258\n",
      "Epoch 517/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5533 - mse: 0.3117 - val_loss: 0.5658 - val_mse: 0.3257\n",
      "Epoch 518/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5500 - mse: 0.3092 - val_loss: 0.5658 - val_mse: 0.3256\n",
      "Epoch 519/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5505 - mse: 0.3091 - val_loss: 0.5654 - val_mse: 0.3252\n",
      "Epoch 520/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5523 - mse: 0.3113 - val_loss: 0.5651 - val_mse: 0.3248\n",
      "Epoch 521/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5530 - mse: 0.3118 - val_loss: 0.5653 - val_mse: 0.3250\n",
      "Epoch 522/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5519 - mse: 0.3106 - val_loss: 0.5647 - val_mse: 0.3243\n",
      "Epoch 523/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5513 - mse: 0.3100 - val_loss: 0.5646 - val_mse: 0.3242\n",
      "Epoch 524/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5532 - mse: 0.3122 - val_loss: 0.5646 - val_mse: 0.3243\n",
      "Epoch 525/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5504 - mse: 0.3092 - val_loss: 0.5648 - val_mse: 0.3244\n",
      "Epoch 526/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5498 - mse: 0.3082 - val_loss: 0.5644 - val_mse: 0.3241\n",
      "Epoch 527/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5518 - mse: 0.3103 - val_loss: 0.5642 - val_mse: 0.3237\n",
      "Epoch 528/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5497 - mse: 0.3080 - val_loss: 0.5643 - val_mse: 0.3239\n",
      "Epoch 529/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5496 - mse: 0.3077 - val_loss: 0.5638 - val_mse: 0.3233\n",
      "Epoch 530/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5494 - mse: 0.3079 - val_loss: 0.5638 - val_mse: 0.3233\n",
      "Epoch 531/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5503 - mse: 0.3089 - val_loss: 0.5635 - val_mse: 0.3229\n",
      "Epoch 532/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5487 - mse: 0.3073 - val_loss: 0.5632 - val_mse: 0.3226\n",
      "Epoch 533/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5505 - mse: 0.3088 - val_loss: 0.5633 - val_mse: 0.3227\n",
      "Epoch 534/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5489 - mse: 0.3070 - val_loss: 0.5630 - val_mse: 0.3224\n",
      "Epoch 535/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5477 - mse: 0.3059 - val_loss: 0.5630 - val_mse: 0.3224\n",
      "Epoch 536/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5509 - mse: 0.3096 - val_loss: 0.5625 - val_mse: 0.3219\n",
      "Epoch 537/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5486 - mse: 0.3069 - val_loss: 0.5624 - val_mse: 0.3218\n",
      "Epoch 538/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5473 - mse: 0.3049 - val_loss: 0.5622 - val_mse: 0.3215\n",
      "Epoch 539/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5481 - mse: 0.3062 - val_loss: 0.5624 - val_mse: 0.3217\n",
      "Epoch 540/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5485 - mse: 0.3070 - val_loss: 0.5620 - val_mse: 0.3213\n",
      "Epoch 541/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5486 - mse: 0.3065 - val_loss: 0.5620 - val_mse: 0.3212\n",
      "Epoch 542/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5489 - mse: 0.3069 - val_loss: 0.5620 - val_mse: 0.3213\n",
      "Epoch 543/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5458 - mse: 0.3040 - val_loss: 0.5619 - val_mse: 0.3211\n",
      "Epoch 544/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5454 - mse: 0.3032 - val_loss: 0.5618 - val_mse: 0.3210\n",
      "Epoch 545/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5462 - mse: 0.3041 - val_loss: 0.5613 - val_mse: 0.3204\n",
      "Epoch 546/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5475 - mse: 0.3060 - val_loss: 0.5614 - val_mse: 0.3206\n",
      "Epoch 547/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5478 - mse: 0.3058 - val_loss: 0.5614 - val_mse: 0.3205\n",
      "Epoch 548/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5450 - mse: 0.3030 - val_loss: 0.5611 - val_mse: 0.3202\n",
      "Epoch 549/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5454 - mse: 0.3041 - val_loss: 0.5607 - val_mse: 0.3198\n",
      "Epoch 550/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5473 - mse: 0.3053 - val_loss: 0.5605 - val_mse: 0.3196\n",
      "Epoch 551/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5465 - mse: 0.3050 - val_loss: 0.5606 - val_mse: 0.3197\n",
      "Epoch 552/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5463 - mse: 0.3043 - val_loss: 0.5606 - val_mse: 0.3196\n",
      "Epoch 553/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5447 - mse: 0.3028 - val_loss: 0.5601 - val_mse: 0.3191\n",
      "Epoch 554/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5446 - mse: 0.3026 - val_loss: 0.5601 - val_mse: 0.3190\n",
      "Epoch 555/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5434 - mse: 0.3011 - val_loss: 0.5598 - val_mse: 0.3187\n",
      "Epoch 556/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5456 - mse: 0.3039 - val_loss: 0.5596 - val_mse: 0.3185\n",
      "Epoch 557/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5434 - mse: 0.3013 - val_loss: 0.5599 - val_mse: 0.3189\n",
      "Epoch 558/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5445 - mse: 0.3024 - val_loss: 0.5598 - val_mse: 0.3187\n",
      "Epoch 559/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5435 - mse: 0.3015 - val_loss: 0.5596 - val_mse: 0.3185\n",
      "Epoch 560/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5433 - mse: 0.3009 - val_loss: 0.5595 - val_mse: 0.3183\n",
      "Epoch 561/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5443 - mse: 0.3023 - val_loss: 0.5590 - val_mse: 0.3178\n",
      "Epoch 562/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5426 - mse: 0.3001 - val_loss: 0.5588 - val_mse: 0.3176\n",
      "Epoch 563/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5412 - mse: 0.2988 - val_loss: 0.5589 - val_mse: 0.3177\n",
      "Epoch 564/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5413 - mse: 0.2994 - val_loss: 0.5590 - val_mse: 0.3178\n",
      "Epoch 565/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5430 - mse: 0.3005 - val_loss: 0.5590 - val_mse: 0.3178\n",
      "Epoch 566/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5428 - mse: 0.3010 - val_loss: 0.5586 - val_mse: 0.3174\n",
      "Epoch 567/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5409 - mse: 0.2979 - val_loss: 0.5586 - val_mse: 0.3174\n",
      "Epoch 568/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5423 - mse: 0.2996 - val_loss: 0.5584 - val_mse: 0.3171\n",
      "Epoch 569/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5434 - mse: 0.3011 - val_loss: 0.5578 - val_mse: 0.3165\n",
      "Epoch 570/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5410 - mse: 0.2982 - val_loss: 0.5580 - val_mse: 0.3167\n",
      "Epoch 571/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5417 - mse: 0.2988 - val_loss: 0.5577 - val_mse: 0.3163\n",
      "Epoch 572/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5422 - mse: 0.3002 - val_loss: 0.5577 - val_mse: 0.3163\n",
      "Epoch 573/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5402 - mse: 0.2982 - val_loss: 0.5577 - val_mse: 0.3163\n",
      "Epoch 574/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5417 - mse: 0.2994 - val_loss: 0.5575 - val_mse: 0.3161\n",
      "Epoch 575/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5396 - mse: 0.2972 - val_loss: 0.5573 - val_mse: 0.3159\n",
      "Epoch 576/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5407 - mse: 0.2981 - val_loss: 0.5571 - val_mse: 0.3157\n",
      "Epoch 577/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5393 - mse: 0.2971 - val_loss: 0.5574 - val_mse: 0.3159\n",
      "Epoch 578/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5430 - mse: 0.3003 - val_loss: 0.5569 - val_mse: 0.3154\n",
      "Epoch 579/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5398 - mse: 0.2975 - val_loss: 0.5571 - val_mse: 0.3156\n",
      "Epoch 580/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5399 - mse: 0.2970 - val_loss: 0.5568 - val_mse: 0.3153\n",
      "Epoch 581/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5409 - mse: 0.2984 - val_loss: 0.5569 - val_mse: 0.3154\n",
      "Epoch 582/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5397 - mse: 0.2965 - val_loss: 0.5564 - val_mse: 0.3149\n",
      "Epoch 583/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5384 - mse: 0.2962 - val_loss: 0.5568 - val_mse: 0.3152\n",
      "Epoch 584/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5391 - mse: 0.2966 - val_loss: 0.5563 - val_mse: 0.3148\n",
      "Epoch 585/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5383 - mse: 0.2955 - val_loss: 0.5563 - val_mse: 0.3147\n",
      "Epoch 586/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5377 - mse: 0.2956 - val_loss: 0.5562 - val_mse: 0.3146\n",
      "Epoch 587/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5400 - mse: 0.2971 - val_loss: 0.5560 - val_mse: 0.3144\n",
      "Epoch 588/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5392 - mse: 0.2965 - val_loss: 0.5556 - val_mse: 0.3139\n",
      "Epoch 589/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5403 - mse: 0.2979 - val_loss: 0.5559 - val_mse: 0.3142\n",
      "Epoch 590/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5362 - mse: 0.2936 - val_loss: 0.5559 - val_mse: 0.3143\n",
      "Epoch 591/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5348 - mse: 0.2921 - val_loss: 0.5557 - val_mse: 0.3141\n",
      "Epoch 592/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5377 - mse: 0.2949 - val_loss: 0.5560 - val_mse: 0.3144\n",
      "Epoch 593/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5381 - mse: 0.2956 - val_loss: 0.5557 - val_mse: 0.3140\n",
      "Epoch 594/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5368 - mse: 0.2943 - val_loss: 0.5551 - val_mse: 0.3134\n",
      "Epoch 595/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5370 - mse: 0.2938 - val_loss: 0.5549 - val_mse: 0.3132\n",
      "Epoch 596/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5379 - mse: 0.2949 - val_loss: 0.5554 - val_mse: 0.3136\n",
      "Epoch 597/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5370 - mse: 0.2943 - val_loss: 0.5547 - val_mse: 0.3129\n",
      "Epoch 598/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5367 - mse: 0.2934 - val_loss: 0.5547 - val_mse: 0.3129\n",
      "Epoch 599/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5357 - mse: 0.2923 - val_loss: 0.5547 - val_mse: 0.3129\n",
      "Epoch 600/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5382 - mse: 0.2951 - val_loss: 0.5545 - val_mse: 0.3127\n",
      "Epoch 601/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5373 - mse: 0.2947 - val_loss: 0.5545 - val_mse: 0.3126\n",
      "Epoch 602/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5362 - mse: 0.2936 - val_loss: 0.5543 - val_mse: 0.3124\n",
      "Epoch 603/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5350 - mse: 0.2917 - val_loss: 0.5539 - val_mse: 0.3120\n",
      "Epoch 604/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5385 - mse: 0.2954 - val_loss: 0.5542 - val_mse: 0.3123\n",
      "Epoch 605/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5353 - mse: 0.2926 - val_loss: 0.5542 - val_mse: 0.3123\n",
      "Epoch 606/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5363 - mse: 0.2929 - val_loss: 0.5540 - val_mse: 0.3121\n",
      "Epoch 607/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5359 - mse: 0.2932 - val_loss: 0.5541 - val_mse: 0.3122\n",
      "Epoch 608/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5336 - mse: 0.2902 - val_loss: 0.5539 - val_mse: 0.3120\n",
      "Epoch 609/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5345 - mse: 0.2915 - val_loss: 0.5535 - val_mse: 0.3115\n",
      "Epoch 610/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5356 - mse: 0.2926 - val_loss: 0.5539 - val_mse: 0.3120\n",
      "Epoch 611/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5348 - mse: 0.2915 - val_loss: 0.5535 - val_mse: 0.3115\n",
      "Epoch 612/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5341 - mse: 0.2914 - val_loss: 0.5536 - val_mse: 0.3117\n",
      "Epoch 613/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5348 - mse: 0.2917 - val_loss: 0.5536 - val_mse: 0.3117\n",
      "Epoch 614/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5331 - mse: 0.2897 - val_loss: 0.5534 - val_mse: 0.3114\n",
      "Epoch 615/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5337 - mse: 0.2901 - val_loss: 0.5535 - val_mse: 0.3115\n",
      "Epoch 616/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5336 - mse: 0.2905 - val_loss: 0.5534 - val_mse: 0.3114\n",
      "Epoch 617/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5337 - mse: 0.2903 - val_loss: 0.5530 - val_mse: 0.3109\n",
      "Epoch 618/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5350 - mse: 0.2914 - val_loss: 0.5529 - val_mse: 0.3108\n",
      "Epoch 619/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5304 - mse: 0.2871 - val_loss: 0.5529 - val_mse: 0.3108\n",
      "Epoch 620/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5327 - mse: 0.2894 - val_loss: 0.5527 - val_mse: 0.3106\n",
      "Epoch 621/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5326 - mse: 0.2889 - val_loss: 0.5525 - val_mse: 0.3104\n",
      "Epoch 622/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5339 - mse: 0.2905 - val_loss: 0.5525 - val_mse: 0.3104\n",
      "Epoch 623/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5309 - mse: 0.2878 - val_loss: 0.5527 - val_mse: 0.3106\n",
      "Epoch 624/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5305 - mse: 0.2878 - val_loss: 0.5524 - val_mse: 0.3103\n",
      "Epoch 625/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5306 - mse: 0.2876 - val_loss: 0.5523 - val_mse: 0.3101\n",
      "Epoch 626/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5322 - mse: 0.2893 - val_loss: 0.5524 - val_mse: 0.3103\n",
      "Epoch 627/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5319 - mse: 0.2884 - val_loss: 0.5522 - val_mse: 0.3101\n",
      "Epoch 628/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5299 - mse: 0.2864 - val_loss: 0.5517 - val_mse: 0.3095\n",
      "Epoch 629/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5349 - mse: 0.2916 - val_loss: 0.5516 - val_mse: 0.3094\n",
      "Epoch 630/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5325 - mse: 0.2896 - val_loss: 0.5516 - val_mse: 0.3094\n",
      "Epoch 631/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5314 - mse: 0.2884 - val_loss: 0.5516 - val_mse: 0.3094\n",
      "Epoch 632/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5316 - mse: 0.2879 - val_loss: 0.5514 - val_mse: 0.3092\n",
      "Epoch 633/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5298 - mse: 0.2863 - val_loss: 0.5513 - val_mse: 0.3090\n",
      "Epoch 634/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5308 - mse: 0.2868 - val_loss: 0.5513 - val_mse: 0.3091\n",
      "Epoch 635/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5308 - mse: 0.2875 - val_loss: 0.5516 - val_mse: 0.3094\n",
      "Epoch 636/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5302 - mse: 0.2871 - val_loss: 0.5513 - val_mse: 0.3091\n",
      "Epoch 637/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5294 - mse: 0.2864 - val_loss: 0.5513 - val_mse: 0.3090\n",
      "Epoch 638/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5301 - mse: 0.2863 - val_loss: 0.5518 - val_mse: 0.3095\n",
      "Epoch 639/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5301 - mse: 0.2866 - val_loss: 0.5515 - val_mse: 0.3093\n",
      "Epoch 640/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5302 - mse: 0.2869 - val_loss: 0.5510 - val_mse: 0.3087\n",
      "Epoch 641/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5299 - mse: 0.2866 - val_loss: 0.5509 - val_mse: 0.3086\n",
      "Epoch 642/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5288 - mse: 0.2848 - val_loss: 0.5512 - val_mse: 0.3089\n",
      "Epoch 643/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5292 - mse: 0.2858 - val_loss: 0.5510 - val_mse: 0.3087\n",
      "Epoch 644/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5294 - mse: 0.2855 - val_loss: 0.5507 - val_mse: 0.3084\n",
      "Epoch 645/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5292 - mse: 0.2859 - val_loss: 0.5504 - val_mse: 0.3081\n",
      "Epoch 646/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5289 - mse: 0.2859 - val_loss: 0.5507 - val_mse: 0.3084\n",
      "Epoch 647/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5289 - mse: 0.2858 - val_loss: 0.5506 - val_mse: 0.3083\n",
      "Epoch 648/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5279 - mse: 0.2846 - val_loss: 0.5504 - val_mse: 0.3080\n",
      "Epoch 649/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5296 - mse: 0.2860 - val_loss: 0.5501 - val_mse: 0.3077\n",
      "Epoch 650/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5298 - mse: 0.2864 - val_loss: 0.5502 - val_mse: 0.3078\n",
      "Epoch 651/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5291 - mse: 0.2854 - val_loss: 0.5505 - val_mse: 0.3081\n",
      "Epoch 652/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5275 - mse: 0.2837 - val_loss: 0.5501 - val_mse: 0.3077\n",
      "Epoch 653/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5271 - mse: 0.2832 - val_loss: 0.5503 - val_mse: 0.3079\n",
      "Epoch 654/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5259 - mse: 0.2821 - val_loss: 0.5503 - val_mse: 0.3079\n",
      "Epoch 655/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5256 - mse: 0.2820 - val_loss: 0.5502 - val_mse: 0.3078\n",
      "Epoch 656/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5295 - mse: 0.2859 - val_loss: 0.5502 - val_mse: 0.3078\n",
      "Epoch 657/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5279 - mse: 0.2846 - val_loss: 0.5499 - val_mse: 0.3075\n",
      "Epoch 658/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5267 - mse: 0.2825 - val_loss: 0.5497 - val_mse: 0.3072\n",
      "Epoch 659/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5265 - mse: 0.2826 - val_loss: 0.5495 - val_mse: 0.3070\n",
      "Epoch 660/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5277 - mse: 0.2844 - val_loss: 0.5498 - val_mse: 0.3073\n",
      "Epoch 661/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5273 - mse: 0.2835 - val_loss: 0.5493 - val_mse: 0.3067\n",
      "Epoch 662/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5283 - mse: 0.2839 - val_loss: 0.5495 - val_mse: 0.3070\n",
      "Epoch 663/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5265 - mse: 0.2826 - val_loss: 0.5495 - val_mse: 0.3070\n",
      "Epoch 664/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5256 - mse: 0.2812 - val_loss: 0.5494 - val_mse: 0.3069\n",
      "Epoch 665/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5272 - mse: 0.2838 - val_loss: 0.5492 - val_mse: 0.3067\n",
      "Epoch 666/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5272 - mse: 0.2832 - val_loss: 0.5492 - val_mse: 0.3066\n",
      "Epoch 667/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5228 - mse: 0.2790 - val_loss: 0.5493 - val_mse: 0.3068\n",
      "Epoch 668/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5273 - mse: 0.2833 - val_loss: 0.5490 - val_mse: 0.3065\n",
      "Epoch 669/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5241 - mse: 0.2803 - val_loss: 0.5489 - val_mse: 0.3064\n",
      "Epoch 670/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5241 - mse: 0.2808 - val_loss: 0.5491 - val_mse: 0.3065\n",
      "Epoch 671/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5237 - mse: 0.2797 - val_loss: 0.5494 - val_mse: 0.3069\n",
      "Epoch 672/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5262 - mse: 0.2824 - val_loss: 0.5488 - val_mse: 0.3062\n",
      "Epoch 673/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5266 - mse: 0.2829 - val_loss: 0.5487 - val_mse: 0.3061\n",
      "Epoch 674/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5249 - mse: 0.2812 - val_loss: 0.5487 - val_mse: 0.3061\n",
      "Epoch 675/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5256 - mse: 0.2815 - val_loss: 0.5485 - val_mse: 0.3058\n",
      "Epoch 676/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5232 - mse: 0.2797 - val_loss: 0.5485 - val_mse: 0.3059\n",
      "Epoch 677/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5238 - mse: 0.2802 - val_loss: 0.5483 - val_mse: 0.3056\n",
      "Epoch 678/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5233 - mse: 0.2796 - val_loss: 0.5484 - val_mse: 0.3057\n",
      "Epoch 679/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5235 - mse: 0.2801 - val_loss: 0.5487 - val_mse: 0.3061\n",
      "Epoch 680/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5227 - mse: 0.2787 - val_loss: 0.5483 - val_mse: 0.3056\n",
      "Epoch 681/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5233 - mse: 0.2798 - val_loss: 0.5481 - val_mse: 0.3055\n",
      "Epoch 682/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5231 - mse: 0.2794 - val_loss: 0.5479 - val_mse: 0.3052\n",
      "Epoch 683/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5248 - mse: 0.2809 - val_loss: 0.5478 - val_mse: 0.3051\n",
      "Epoch 684/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5229 - mse: 0.2787 - val_loss: 0.5481 - val_mse: 0.3055\n",
      "Epoch 685/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5228 - mse: 0.2783 - val_loss: 0.5481 - val_mse: 0.3054\n",
      "Epoch 686/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5224 - mse: 0.2779 - val_loss: 0.5479 - val_mse: 0.3052\n",
      "Epoch 687/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5241 - mse: 0.2802 - val_loss: 0.5478 - val_mse: 0.3051\n",
      "Epoch 688/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5222 - mse: 0.2777 - val_loss: 0.5478 - val_mse: 0.3051\n",
      "Epoch 689/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5229 - mse: 0.2794 - val_loss: 0.5479 - val_mse: 0.3052\n",
      "Epoch 690/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5217 - mse: 0.2782 - val_loss: 0.5479 - val_mse: 0.3052\n",
      "Epoch 691/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5214 - mse: 0.2774 - val_loss: 0.5475 - val_mse: 0.3048\n",
      "Epoch 692/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5214 - mse: 0.2775 - val_loss: 0.5476 - val_mse: 0.3048\n",
      "Epoch 693/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5240 - mse: 0.2801 - val_loss: 0.5477 - val_mse: 0.3050\n",
      "Epoch 694/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5211 - mse: 0.2770 - val_loss: 0.5474 - val_mse: 0.3046\n",
      "Epoch 695/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5212 - mse: 0.2773 - val_loss: 0.5478 - val_mse: 0.3051\n",
      "Epoch 696/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5211 - mse: 0.2768 - val_loss: 0.5471 - val_mse: 0.3044\n",
      "Epoch 697/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5216 - mse: 0.2775 - val_loss: 0.5471 - val_mse: 0.3043\n",
      "Epoch 698/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5225 - mse: 0.2788 - val_loss: 0.5471 - val_mse: 0.3043\n",
      "Epoch 699/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5225 - mse: 0.2789 - val_loss: 0.5476 - val_mse: 0.3048\n",
      "Epoch 700/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5202 - mse: 0.2759 - val_loss: 0.5472 - val_mse: 0.3044\n",
      "Epoch 701/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5187 - mse: 0.2747 - val_loss: 0.5467 - val_mse: 0.3039\n",
      "Epoch 702/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5220 - mse: 0.2778 - val_loss: 0.5470 - val_mse: 0.3042\n",
      "Epoch 703/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5226 - mse: 0.2787 - val_loss: 0.5469 - val_mse: 0.3040\n",
      "Epoch 704/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5202 - mse: 0.2761 - val_loss: 0.5469 - val_mse: 0.3041\n",
      "Epoch 705/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5215 - mse: 0.2771 - val_loss: 0.5468 - val_mse: 0.3040\n",
      "Epoch 706/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5203 - mse: 0.2766 - val_loss: 0.5469 - val_mse: 0.3041\n",
      "Epoch 707/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5191 - mse: 0.2751 - val_loss: 0.5466 - val_mse: 0.3037\n",
      "Epoch 708/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5184 - mse: 0.2743 - val_loss: 0.5469 - val_mse: 0.3041\n",
      "Epoch 709/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5193 - mse: 0.2752 - val_loss: 0.5467 - val_mse: 0.3038\n",
      "Epoch 710/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5198 - mse: 0.2761 - val_loss: 0.5465 - val_mse: 0.3036\n",
      "Epoch 711/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5214 - mse: 0.2769 - val_loss: 0.5466 - val_mse: 0.3037\n",
      "Epoch 712/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5191 - mse: 0.2745 - val_loss: 0.5465 - val_mse: 0.3036\n",
      "Epoch 713/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5184 - mse: 0.2742 - val_loss: 0.5465 - val_mse: 0.3036\n",
      "Epoch 714/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5183 - mse: 0.2739 - val_loss: 0.5468 - val_mse: 0.3040\n",
      "Epoch 715/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5177 - mse: 0.2733 - val_loss: 0.5463 - val_mse: 0.3034\n",
      "Epoch 716/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5187 - mse: 0.2749 - val_loss: 0.5463 - val_mse: 0.3034\n",
      "Epoch 717/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5195 - mse: 0.2751 - val_loss: 0.5462 - val_mse: 0.3033\n",
      "Epoch 718/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5194 - mse: 0.2752 - val_loss: 0.5463 - val_mse: 0.3034\n",
      "Epoch 719/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5201 - mse: 0.2756 - val_loss: 0.5462 - val_mse: 0.3033\n",
      "Epoch 720/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5169 - mse: 0.2727 - val_loss: 0.5461 - val_mse: 0.3032\n",
      "Epoch 721/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5174 - mse: 0.2732 - val_loss: 0.5462 - val_mse: 0.3033\n",
      "Epoch 722/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5186 - mse: 0.2740 - val_loss: 0.5463 - val_mse: 0.3034\n",
      "Epoch 723/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5178 - mse: 0.2735 - val_loss: 0.5462 - val_mse: 0.3033\n",
      "Epoch 724/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5160 - mse: 0.2721 - val_loss: 0.5459 - val_mse: 0.3030\n",
      "Epoch 725/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5181 - mse: 0.2734 - val_loss: 0.5458 - val_mse: 0.3029\n",
      "Epoch 726/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5193 - mse: 0.2748 - val_loss: 0.5459 - val_mse: 0.3029\n",
      "Epoch 727/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5179 - mse: 0.2737 - val_loss: 0.5461 - val_mse: 0.3032\n",
      "Epoch 728/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5166 - mse: 0.2726 - val_loss: 0.5457 - val_mse: 0.3027\n",
      "Epoch 729/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5164 - mse: 0.2722 - val_loss: 0.5461 - val_mse: 0.3032\n",
      "Epoch 730/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5184 - mse: 0.2738 - val_loss: 0.5457 - val_mse: 0.3027\n",
      "Epoch 731/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5167 - mse: 0.2723 - val_loss: 0.5459 - val_mse: 0.3030\n",
      "Epoch 732/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5165 - mse: 0.2720 - val_loss: 0.5456 - val_mse: 0.3026\n",
      "Epoch 733/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5169 - mse: 0.2727 - val_loss: 0.5452 - val_mse: 0.3022\n",
      "Epoch 734/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5142 - mse: 0.2701 - val_loss: 0.5457 - val_mse: 0.3027\n",
      "Epoch 735/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5157 - mse: 0.2710 - val_loss: 0.5454 - val_mse: 0.3024\n",
      "Epoch 736/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5162 - mse: 0.2716 - val_loss: 0.5455 - val_mse: 0.3025\n",
      "Epoch 737/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5161 - mse: 0.2717 - val_loss: 0.5455 - val_mse: 0.3026\n",
      "Epoch 738/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5166 - mse: 0.2719 - val_loss: 0.5454 - val_mse: 0.3024\n",
      "Epoch 739/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5170 - mse: 0.2724 - val_loss: 0.5456 - val_mse: 0.3026\n",
      "Epoch 740/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5160 - mse: 0.2712 - val_loss: 0.5453 - val_mse: 0.3023\n",
      "Epoch 741/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5162 - mse: 0.2710 - val_loss: 0.5450 - val_mse: 0.3020\n",
      "Epoch 742/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5161 - mse: 0.2719 - val_loss: 0.5452 - val_mse: 0.3022\n",
      "Epoch 743/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5136 - mse: 0.2688 - val_loss: 0.5452 - val_mse: 0.3022\n",
      "Epoch 744/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5164 - mse: 0.2720 - val_loss: 0.5449 - val_mse: 0.3019\n",
      "Epoch 745/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5171 - mse: 0.2721 - val_loss: 0.5450 - val_mse: 0.3020\n",
      "Epoch 746/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5152 - mse: 0.2704 - val_loss: 0.5451 - val_mse: 0.3021\n",
      "Epoch 747/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5149 - mse: 0.2706 - val_loss: 0.5449 - val_mse: 0.3019\n",
      "Epoch 748/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5148 - mse: 0.2708 - val_loss: 0.5449 - val_mse: 0.3019\n",
      "Epoch 749/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5144 - mse: 0.2701 - val_loss: 0.5447 - val_mse: 0.3017\n",
      "Epoch 750/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5131 - mse: 0.2686 - val_loss: 0.5450 - val_mse: 0.3019\n",
      "Epoch 751/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5153 - mse: 0.2709 - val_loss: 0.5447 - val_mse: 0.3017\n",
      "Epoch 752/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5128 - mse: 0.2683 - val_loss: 0.5447 - val_mse: 0.3016\n",
      "Epoch 753/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5161 - mse: 0.2720 - val_loss: 0.5446 - val_mse: 0.3016\n",
      "Epoch 754/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5108 - mse: 0.2660 - val_loss: 0.5445 - val_mse: 0.3014\n",
      "Epoch 755/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5137 - mse: 0.2688 - val_loss: 0.5448 - val_mse: 0.3017\n",
      "Epoch 756/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5138 - mse: 0.2692 - val_loss: 0.5444 - val_mse: 0.3013\n",
      "Epoch 757/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5146 - mse: 0.2700 - val_loss: 0.5447 - val_mse: 0.3016\n",
      "Epoch 758/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5143 - mse: 0.2698 - val_loss: 0.5446 - val_mse: 0.3016\n",
      "Epoch 759/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5130 - mse: 0.2689 - val_loss: 0.5444 - val_mse: 0.3013\n",
      "Epoch 760/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5147 - mse: 0.2698 - val_loss: 0.5442 - val_mse: 0.3011\n",
      "Epoch 761/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5156 - mse: 0.2709 - val_loss: 0.5442 - val_mse: 0.3011\n",
      "Epoch 762/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5125 - mse: 0.2686 - val_loss: 0.5445 - val_mse: 0.3014\n",
      "Epoch 763/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5122 - mse: 0.2676 - val_loss: 0.5445 - val_mse: 0.3014\n",
      "Epoch 764/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5117 - mse: 0.2677 - val_loss: 0.5445 - val_mse: 0.3014\n",
      "Epoch 765/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5131 - mse: 0.2688 - val_loss: 0.5443 - val_mse: 0.3012\n",
      "Epoch 766/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5128 - mse: 0.2685 - val_loss: 0.5444 - val_mse: 0.3013\n",
      "Epoch 767/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5099 - mse: 0.2649 - val_loss: 0.5439 - val_mse: 0.3008\n",
      "Epoch 768/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5107 - mse: 0.2665 - val_loss: 0.5445 - val_mse: 0.3014\n",
      "Epoch 769/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5100 - mse: 0.2659 - val_loss: 0.5443 - val_mse: 0.3012\n",
      "Epoch 770/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5136 - mse: 0.2686 - val_loss: 0.5440 - val_mse: 0.3008\n",
      "Epoch 771/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5135 - mse: 0.2690 - val_loss: 0.5439 - val_mse: 0.3007\n",
      "Epoch 772/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5138 - mse: 0.2695 - val_loss: 0.5440 - val_mse: 0.3008\n",
      "Epoch 773/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5108 - mse: 0.2664 - val_loss: 0.5440 - val_mse: 0.3008\n",
      "Epoch 774/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5120 - mse: 0.2671 - val_loss: 0.5439 - val_mse: 0.3007\n",
      "Epoch 775/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5119 - mse: 0.2673 - val_loss: 0.5438 - val_mse: 0.3006\n",
      "Epoch 776/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5122 - mse: 0.2677 - val_loss: 0.5438 - val_mse: 0.3007\n",
      "Epoch 777/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5133 - mse: 0.2683 - val_loss: 0.5436 - val_mse: 0.3004\n",
      "Epoch 778/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5101 - mse: 0.2657 - val_loss: 0.5435 - val_mse: 0.3004\n",
      "Epoch 779/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5119 - mse: 0.2674 - val_loss: 0.5437 - val_mse: 0.3006\n",
      "Epoch 780/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5092 - mse: 0.2648 - val_loss: 0.5435 - val_mse: 0.3003\n",
      "Epoch 781/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5096 - mse: 0.2649 - val_loss: 0.5435 - val_mse: 0.3003\n",
      "Epoch 782/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5119 - mse: 0.2675 - val_loss: 0.5436 - val_mse: 0.3004\n",
      "Epoch 783/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5099 - mse: 0.2649 - val_loss: 0.5434 - val_mse: 0.3002\n",
      "Epoch 784/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5086 - mse: 0.2643 - val_loss: 0.5436 - val_mse: 0.3004\n",
      "Epoch 785/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5082 - mse: 0.2638 - val_loss: 0.5434 - val_mse: 0.3002\n",
      "Epoch 786/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5086 - mse: 0.2641 - val_loss: 0.5436 - val_mse: 0.3004\n",
      "Epoch 787/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5081 - mse: 0.2635 - val_loss: 0.5432 - val_mse: 0.3000\n",
      "Epoch 788/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5109 - mse: 0.2664 - val_loss: 0.5434 - val_mse: 0.3002\n",
      "Epoch 789/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5095 - mse: 0.2648 - val_loss: 0.5433 - val_mse: 0.3001\n",
      "Epoch 790/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5091 - mse: 0.2643 - val_loss: 0.5433 - val_mse: 0.3001\n",
      "Epoch 791/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5094 - mse: 0.2650 - val_loss: 0.5438 - val_mse: 0.3006\n",
      "Epoch 792/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5092 - mse: 0.2648 - val_loss: 0.5431 - val_mse: 0.2998\n",
      "Epoch 793/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5083 - mse: 0.2640 - val_loss: 0.5431 - val_mse: 0.2999\n",
      "Epoch 794/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5086 - mse: 0.2641 - val_loss: 0.5429 - val_mse: 0.2997\n",
      "Epoch 795/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5085 - mse: 0.2636 - val_loss: 0.5434 - val_mse: 0.3002\n",
      "Epoch 796/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5080 - mse: 0.2635 - val_loss: 0.5432 - val_mse: 0.2999\n",
      "Epoch 797/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5078 - mse: 0.2633 - val_loss: 0.5432 - val_mse: 0.2999\n",
      "Epoch 798/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5084 - mse: 0.2635 - val_loss: 0.5430 - val_mse: 0.2998\n",
      "Epoch 799/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5094 - mse: 0.2646 - val_loss: 0.5430 - val_mse: 0.2998\n",
      "Epoch 800/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5076 - mse: 0.2625 - val_loss: 0.5429 - val_mse: 0.2997\n",
      "Epoch 801/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5061 - mse: 0.2610 - val_loss: 0.5430 - val_mse: 0.2997\n",
      "Epoch 802/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5060 - mse: 0.2609 - val_loss: 0.5427 - val_mse: 0.2994\n",
      "Epoch 803/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5068 - mse: 0.2621 - val_loss: 0.5430 - val_mse: 0.2998\n",
      "Epoch 804/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5082 - mse: 0.2632 - val_loss: 0.5426 - val_mse: 0.2993\n",
      "Epoch 805/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5058 - mse: 0.2613 - val_loss: 0.5427 - val_mse: 0.2994\n",
      "Epoch 806/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5062 - mse: 0.2616 - val_loss: 0.5430 - val_mse: 0.2997\n",
      "Epoch 807/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5073 - mse: 0.2624 - val_loss: 0.5430 - val_mse: 0.2997\n",
      "Epoch 808/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5068 - mse: 0.2622 - val_loss: 0.5428 - val_mse: 0.2995\n",
      "Epoch 809/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5078 - mse: 0.2627 - val_loss: 0.5427 - val_mse: 0.2994\n",
      "Epoch 810/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5069 - mse: 0.2619 - val_loss: 0.5430 - val_mse: 0.2997\n",
      "Epoch 811/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5042 - mse: 0.2595 - val_loss: 0.5426 - val_mse: 0.2993\n",
      "Epoch 812/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5062 - mse: 0.2611 - val_loss: 0.5427 - val_mse: 0.2994\n",
      "Epoch 813/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5064 - mse: 0.2613 - val_loss: 0.5428 - val_mse: 0.2995\n",
      "Epoch 814/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - mse: 0.2609 - val_loss: 0.5429 - val_mse: 0.2996\n",
      "Epoch 815/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5055 - mse: 0.2608 - val_loss: 0.5428 - val_mse: 0.2995\n",
      "Epoch 816/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5045 - mse: 0.2595 - val_loss: 0.5426 - val_mse: 0.2993\n",
      "Epoch 817/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5051 - mse: 0.2603 - val_loss: 0.5426 - val_mse: 0.2993\n",
      "Epoch 818/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5055 - mse: 0.2610 - val_loss: 0.5424 - val_mse: 0.2991\n",
      "Epoch 819/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5064 - mse: 0.2619 - val_loss: 0.5427 - val_mse: 0.2994\n",
      "Epoch 820/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5037 - mse: 0.2590 - val_loss: 0.5423 - val_mse: 0.2990\n",
      "Epoch 821/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5047 - mse: 0.2598 - val_loss: 0.5425 - val_mse: 0.2992\n",
      "Epoch 822/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5050 - mse: 0.2606 - val_loss: 0.5425 - val_mse: 0.2992\n",
      "Epoch 823/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5030 - mse: 0.2586 - val_loss: 0.5422 - val_mse: 0.2989\n",
      "Epoch 824/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5056 - mse: 0.2611 - val_loss: 0.5424 - val_mse: 0.2991\n",
      "Epoch 825/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5044 - mse: 0.2596 - val_loss: 0.5425 - val_mse: 0.2992\n",
      "Epoch 826/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5050 - mse: 0.2604 - val_loss: 0.5423 - val_mse: 0.2989\n",
      "Epoch 827/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5033 - mse: 0.2583 - val_loss: 0.5426 - val_mse: 0.2993\n",
      "Epoch 828/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5056 - mse: 0.2610 - val_loss: 0.5422 - val_mse: 0.2989\n",
      "Epoch 829/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5048 - mse: 0.2599 - val_loss: 0.5424 - val_mse: 0.2991\n",
      "Epoch 830/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5044 - mse: 0.2593 - val_loss: 0.5422 - val_mse: 0.2988\n",
      "Epoch 831/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5048 - mse: 0.2602 - val_loss: 0.5422 - val_mse: 0.2989\n",
      "Epoch 832/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5047 - mse: 0.2599 - val_loss: 0.5421 - val_mse: 0.2987\n",
      "Epoch 833/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5054 - mse: 0.2601 - val_loss: 0.5421 - val_mse: 0.2987\n",
      "Epoch 834/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5036 - mse: 0.2586 - val_loss: 0.5421 - val_mse: 0.2987\n",
      "Epoch 835/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5022 - mse: 0.2572 - val_loss: 0.5418 - val_mse: 0.2984\n",
      "Epoch 836/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.5019 - mse: 0.2570 - val_loss: 0.5418 - val_mse: 0.2984\n",
      "Epoch 837/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5037 - mse: 0.2587 - val_loss: 0.5419 - val_mse: 0.2985\n",
      "Epoch 838/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5035 - mse: 0.2585 - val_loss: 0.5422 - val_mse: 0.2988\n",
      "Epoch 839/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5045 - mse: 0.2595 - val_loss: 0.5420 - val_mse: 0.2987\n",
      "Epoch 840/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5029 - mse: 0.2585 - val_loss: 0.5420 - val_mse: 0.2986\n",
      "Epoch 841/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5041 - mse: 0.2590 - val_loss: 0.5419 - val_mse: 0.2985\n",
      "Epoch 842/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5036 - mse: 0.2586 - val_loss: 0.5417 - val_mse: 0.2983\n",
      "Epoch 843/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5017 - mse: 0.2564 - val_loss: 0.5418 - val_mse: 0.2984\n",
      "Epoch 844/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5025 - mse: 0.2576 - val_loss: 0.5417 - val_mse: 0.2983\n",
      "Epoch 845/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5030 - mse: 0.2583 - val_loss: 0.5418 - val_mse: 0.2984\n",
      "Epoch 846/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5047 - mse: 0.2595 - val_loss: 0.5417 - val_mse: 0.2983\n",
      "Epoch 847/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5017 - mse: 0.2569 - val_loss: 0.5419 - val_mse: 0.2986\n",
      "Epoch 848/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5030 - mse: 0.2578 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 849/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5018 - mse: 0.2572 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 850/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5024 - mse: 0.2573 - val_loss: 0.5418 - val_mse: 0.2984\n",
      "Epoch 851/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5022 - mse: 0.2575 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 852/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5011 - mse: 0.2560 - val_loss: 0.5419 - val_mse: 0.2985\n",
      "Epoch 853/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5026 - mse: 0.2576 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 854/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5023 - mse: 0.2575 - val_loss: 0.5416 - val_mse: 0.2982\n",
      "Epoch 855/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5025 - mse: 0.2574 - val_loss: 0.5416 - val_mse: 0.2982\n",
      "Epoch 856/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4992 - mse: 0.2537 - val_loss: 0.5416 - val_mse: 0.2982\n",
      "Epoch 857/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5014 - mse: 0.2562 - val_loss: 0.5414 - val_mse: 0.2980\n",
      "Epoch 858/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5001 - mse: 0.2552 - val_loss: 0.5413 - val_mse: 0.2979\n",
      "Epoch 859/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5024 - mse: 0.2572 - val_loss: 0.5414 - val_mse: 0.2980\n",
      "Epoch 860/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - mse: 0.2556 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 861/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5012 - mse: 0.2561 - val_loss: 0.5414 - val_mse: 0.2980\n",
      "Epoch 862/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4996 - mse: 0.2549 - val_loss: 0.5413 - val_mse: 0.2979\n",
      "Epoch 863/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5006 - mse: 0.2556 - val_loss: 0.5414 - val_mse: 0.2980\n",
      "Epoch 864/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5006 - mse: 0.2556 - val_loss: 0.5414 - val_mse: 0.2980\n",
      "Epoch 865/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4988 - mse: 0.2534 - val_loss: 0.5415 - val_mse: 0.2981\n",
      "Epoch 866/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4999 - mse: 0.2549 - val_loss: 0.5415 - val_mse: 0.2980\n",
      "Epoch 867/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4990 - mse: 0.2537 - val_loss: 0.5412 - val_mse: 0.2977\n",
      "Epoch 868/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4999 - mse: 0.2548 - val_loss: 0.5414 - val_mse: 0.2979\n",
      "Epoch 869/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4990 - mse: 0.2540 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 870/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5009 - mse: 0.2561 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 871/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4979 - mse: 0.2527 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 872/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4995 - mse: 0.2546 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 873/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4990 - mse: 0.2538 - val_loss: 0.5410 - val_mse: 0.2976\n",
      "Epoch 874/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4991 - mse: 0.2542 - val_loss: 0.5409 - val_mse: 0.2975\n",
      "Epoch 875/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4983 - mse: 0.2538 - val_loss: 0.5410 - val_mse: 0.2975\n",
      "Epoch 876/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4983 - mse: 0.2533 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 877/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4990 - mse: 0.2541 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 878/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4980 - mse: 0.2530 - val_loss: 0.5410 - val_mse: 0.2975\n",
      "Epoch 879/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4981 - mse: 0.2532 - val_loss: 0.5411 - val_mse: 0.2977\n",
      "Epoch 880/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4973 - mse: 0.2524 - val_loss: 0.5411 - val_mse: 0.2977\n",
      "Epoch 881/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4970 - mse: 0.2520 - val_loss: 0.5410 - val_mse: 0.2976\n",
      "Epoch 882/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4977 - mse: 0.2528 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 883/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4980 - mse: 0.2529 - val_loss: 0.5409 - val_mse: 0.2975\n",
      "Epoch 884/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4985 - mse: 0.2532 - val_loss: 0.5408 - val_mse: 0.2974\n",
      "Epoch 885/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4976 - mse: 0.2522 - val_loss: 0.5411 - val_mse: 0.2976\n",
      "Epoch 886/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4973 - mse: 0.2523 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 887/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4991 - mse: 0.2539 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 888/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4982 - mse: 0.2532 - val_loss: 0.5408 - val_mse: 0.2973\n",
      "Epoch 889/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4986 - mse: 0.2534 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 890/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4961 - mse: 0.2515 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 891/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4973 - mse: 0.2529 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 892/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4974 - mse: 0.2524 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 893/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4963 - mse: 0.2513 - val_loss: 0.5408 - val_mse: 0.2974\n",
      "Epoch 894/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4974 - mse: 0.2525 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 895/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4962 - mse: 0.2514 - val_loss: 0.5410 - val_mse: 0.2976\n",
      "Epoch 896/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4959 - mse: 0.2509 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 897/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4965 - mse: 0.2510 - val_loss: 0.5408 - val_mse: 0.2974\n",
      "Epoch 898/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4951 - mse: 0.2500 - val_loss: 0.5406 - val_mse: 0.2971\n",
      "Epoch 899/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4967 - mse: 0.2516 - val_loss: 0.5409 - val_mse: 0.2974\n",
      "Epoch 900/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4952 - mse: 0.2499 - val_loss: 0.5410 - val_mse: 0.2976\n",
      "Epoch 901/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4957 - mse: 0.2508 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 902/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4949 - mse: 0.2503 - val_loss: 0.5408 - val_mse: 0.2973\n",
      "Epoch 903/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4954 - mse: 0.2505 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 904/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4952 - mse: 0.2503 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 905/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4956 - mse: 0.2503 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 906/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4950 - mse: 0.2504 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 907/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - mse: 0.2509 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 908/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4933 - mse: 0.2487 - val_loss: 0.5403 - val_mse: 0.2968\n",
      "Epoch 909/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4945 - mse: 0.2491 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 910/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4954 - mse: 0.2507 - val_loss: 0.5406 - val_mse: 0.2970\n",
      "Epoch 911/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - mse: 0.2504 - val_loss: 0.5407 - val_mse: 0.2972\n",
      "Epoch 912/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4927 - mse: 0.2476 - val_loss: 0.5406 - val_mse: 0.2971\n",
      "Epoch 913/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4930 - mse: 0.2479 - val_loss: 0.5406 - val_mse: 0.2971\n",
      "Epoch 914/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4935 - mse: 0.2482 - val_loss: 0.5408 - val_mse: 0.2973\n",
      "Epoch 915/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4952 - mse: 0.2501 - val_loss: 0.5408 - val_mse: 0.2973\n",
      "Epoch 916/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4934 - mse: 0.2482 - val_loss: 0.5403 - val_mse: 0.2968\n",
      "Epoch 917/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4929 - mse: 0.2476 - val_loss: 0.5405 - val_mse: 0.2969\n",
      "Epoch 918/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4926 - mse: 0.2478 - val_loss: 0.5406 - val_mse: 0.2971\n",
      "Epoch 919/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4938 - mse: 0.2489 - val_loss: 0.5404 - val_mse: 0.2969\n",
      "Epoch 920/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4942 - mse: 0.2490 - val_loss: 0.5406 - val_mse: 0.2970\n",
      "Epoch 921/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4943 - mse: 0.2492 - val_loss: 0.5403 - val_mse: 0.2967\n",
      "Epoch 922/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4922 - mse: 0.2475 - val_loss: 0.5404 - val_mse: 0.2968\n",
      "Epoch 923/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4930 - mse: 0.2479 - val_loss: 0.5402 - val_mse: 0.2967\n",
      "Epoch 924/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4928 - mse: 0.2480 - val_loss: 0.5407 - val_mse: 0.2971\n",
      "Epoch 925/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4931 - mse: 0.2481 - val_loss: 0.5405 - val_mse: 0.2970\n",
      "Epoch 926/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4921 - mse: 0.2474 - val_loss: 0.5403 - val_mse: 0.2968\n",
      "Epoch 927/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4905 - mse: 0.2451 - val_loss: 0.5410 - val_mse: 0.2975\n",
      "Epoch 928/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4946 - mse: 0.2498 - val_loss: 0.5406 - val_mse: 0.2970\n",
      "Epoch 929/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4928 - mse: 0.2479 - val_loss: 0.5401 - val_mse: 0.2966\n",
      "Epoch 930/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4903 - mse: 0.2456 - val_loss: 0.5400 - val_mse: 0.2965\n",
      "Epoch 931/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4942 - mse: 0.2496 - val_loss: 0.5403 - val_mse: 0.2968\n",
      "Epoch 932/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4924 - mse: 0.2473 - val_loss: 0.5401 - val_mse: 0.2965\n",
      "Epoch 933/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4914 - mse: 0.2464 - val_loss: 0.5401 - val_mse: 0.2965\n",
      "Epoch 934/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4941 - mse: 0.2486 - val_loss: 0.5402 - val_mse: 0.2967\n",
      "Epoch 935/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4915 - mse: 0.2462 - val_loss: 0.5402 - val_mse: 0.2966\n",
      "Epoch 936/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4930 - mse: 0.2480 - val_loss: 0.5402 - val_mse: 0.2966\n",
      "Epoch 937/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4927 - mse: 0.2475 - val_loss: 0.5402 - val_mse: 0.2967\n",
      "Epoch 938/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4909 - mse: 0.2460 - val_loss: 0.5404 - val_mse: 0.2968\n",
      "Epoch 939/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4914 - mse: 0.2468 - val_loss: 0.5400 - val_mse: 0.2964\n",
      "Epoch 940/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - mse: 0.2457 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 941/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4909 - mse: 0.2457 - val_loss: 0.5402 - val_mse: 0.2966\n",
      "Epoch 942/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4901 - mse: 0.2451 - val_loss: 0.5400 - val_mse: 0.2965\n",
      "Epoch 943/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4899 - mse: 0.2442 - val_loss: 0.5401 - val_mse: 0.2965\n",
      "Epoch 944/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - mse: 0.2458 - val_loss: 0.5402 - val_mse: 0.2966\n",
      "Epoch 945/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4890 - mse: 0.2440 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 946/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4875 - mse: 0.2426 - val_loss: 0.5402 - val_mse: 0.2967\n",
      "Epoch 947/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4905 - mse: 0.2452 - val_loss: 0.5401 - val_mse: 0.2965\n",
      "Epoch 948/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4895 - mse: 0.2443 - val_loss: 0.5401 - val_mse: 0.2965\n",
      "Epoch 949/1000\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.4920 - mse: 0.2467 - val_loss: 0.5400 - val_mse: 0.2964\n",
      "Epoch 950/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - mse: 0.2453 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 951/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4880 - mse: 0.2433 - val_loss: 0.5400 - val_mse: 0.2964\n",
      "Epoch 952/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4906 - mse: 0.2451 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 953/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4901 - mse: 0.2452 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 954/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4894 - mse: 0.2445 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 955/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4904 - mse: 0.2453 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 956/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4874 - mse: 0.2428 - val_loss: 0.5400 - val_mse: 0.2965\n",
      "Epoch 957/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4887 - mse: 0.2439 - val_loss: 0.5402 - val_mse: 0.2966\n",
      "Epoch 958/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4884 - mse: 0.2434 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 959/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - mse: 0.2427 - val_loss: 0.5400 - val_mse: 0.2965\n",
      "Epoch 960/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4872 - mse: 0.2422 - val_loss: 0.5400 - val_mse: 0.2964\n",
      "Epoch 961/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4891 - mse: 0.2440 - val_loss: 0.5399 - val_mse: 0.2964\n",
      "Epoch 962/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4890 - mse: 0.2440 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 963/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - mse: 0.2422 - val_loss: 0.5400 - val_mse: 0.2964\n",
      "Epoch 964/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4893 - mse: 0.2444 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 965/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - mse: 0.2423 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 966/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4887 - mse: 0.2435 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 967/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4882 - mse: 0.2430 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 968/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4862 - mse: 0.2413 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 969/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4868 - mse: 0.2420 - val_loss: 0.5402 - val_mse: 0.2967\n",
      "Epoch 970/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4870 - mse: 0.2427 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 971/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4880 - mse: 0.2425 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 972/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - mse: 0.2423 - val_loss: 0.5396 - val_mse: 0.2960\n",
      "Epoch 973/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - mse: 0.2425 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 974/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4849 - mse: 0.2396 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 975/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4859 - mse: 0.2410 - val_loss: 0.5397 - val_mse: 0.2962\n",
      "Epoch 976/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4871 - mse: 0.2422 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 977/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4859 - mse: 0.2409 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 978/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4866 - mse: 0.2416 - val_loss: 0.5396 - val_mse: 0.2961\n",
      "Epoch 979/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4865 - mse: 0.2416 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 980/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4865 - mse: 0.2412 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 981/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4856 - mse: 0.2404 - val_loss: 0.5398 - val_mse: 0.2962\n",
      "Epoch 982/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4864 - mse: 0.2414 - val_loss: 0.5396 - val_mse: 0.2960\n",
      "Epoch 983/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4846 - mse: 0.2394 - val_loss: 0.5396 - val_mse: 0.2960\n",
      "Epoch 984/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4863 - mse: 0.2411 - val_loss: 0.5394 - val_mse: 0.2958\n",
      "Epoch 985/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4857 - mse: 0.2404 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 986/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4865 - mse: 0.2416 - val_loss: 0.5396 - val_mse: 0.2960\n",
      "Epoch 987/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4858 - mse: 0.2412 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 988/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4854 - mse: 0.2404 - val_loss: 0.5394 - val_mse: 0.2958\n",
      "Epoch 989/1000\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4846 - mse: 0.2398 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 990/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4861 - mse: 0.2411 - val_loss: 0.5399 - val_mse: 0.2963\n",
      "Epoch 991/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4845 - mse: 0.2398 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 992/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4854 - mse: 0.2405 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 993/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4843 - mse: 0.2394 - val_loss: 0.5394 - val_mse: 0.2958\n",
      "Epoch 994/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4843 - mse: 0.2393 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 995/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4840 - mse: 0.2394 - val_loss: 0.5394 - val_mse: 0.2958\n",
      "Epoch 996/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4840 - mse: 0.2392 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 997/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4835 - mse: 0.2389 - val_loss: 0.5396 - val_mse: 0.2960\n",
      "Epoch 998/1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4857 - mse: 0.2403 - val_loss: 0.5395 - val_mse: 0.2959\n",
      "Epoch 999/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4837 - mse: 0.2387 - val_loss: 0.5397 - val_mse: 0.2961\n",
      "Epoch 1000/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4814 - mse: 0.2363 - val_loss: 0.5393 - val_mse: 0.2957\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = padded_train, \n",
    "    y = Y_train, \n",
    "    validation_data = (padded_valid, Y_valid),\n",
    "    callbacks = callbacks,\n",
    "    epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['loss'], label = 'train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.box(False)\n",
    "plt.grid(True, alpha = .25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['mse'], label = 'train_MCRMSE')\n",
    "plt.plot(history.history['val_mse'], label = 'val_MCRMSE')\n",
    "plt.box(False)\n",
    "plt.grid(True, alpha = .25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('embeddings_scratch.keras', custom_objects={'MCRMSE':MCRMSE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 09:35:26.025202: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-09-19 09:35:26.637899: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 2ms/step - loss: 0.6112 - mse: 0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 09:35:27.194223: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6112228035926819, 0.3780919313430786]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = model.evaluate(padded_test, Y_test)\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 862us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6135743274599891"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCRMSE(Y_test, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = max_tokens, output_dim = 64, input_length = 1000),    \n",
    "    tf.keras.layers.GRU(64, return_sequences=True),\n",
    "    tf.keras.layers.GRU(64, return_sequences=True),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    tf.keras.layers.GRU(32, return_sequences=False),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdd_n/mambaforge/envs/tf_env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = MCRMSE, metrics = 'mse', optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 1000, 64)          1280000   \n",
      "                                                                 \n",
      " gru_14 (GRU)                (None, 1000, 64)          24960     \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, 1000, 64)          24960     \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 1000, 32)          9408      \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 32)                6336      \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345,862\n",
      "Trainable params: 1,345,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_scratch.keras\", save_best_only=True), \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 11s 94ms/step - loss: 2.7155 - mse: 7.5921 - val_loss: 1.7674 - val_mse: 3.2542\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 1.2227 - mse: 1.6399 - val_loss: 0.9334 - val_mse: 0.9128\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.7829 - mse: 0.6390 - val_loss: 0.7010 - val_mse: 0.5034\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 9s 89ms/step - loss: 0.6638 - mse: 0.4503 - val_loss: 0.6529 - val_mse: 0.4333\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 9s 89ms/step - loss: 0.6496 - mse: 0.4295 - val_loss: 0.6491 - val_mse: 0.4282\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.6485 - mse: 0.4283 - val_loss: 0.6490 - val_mse: 0.4280\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.6456 - mse: 0.4243 - val_loss: 0.6456 - val_mse: 0.4237\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.6351 - mse: 0.4105 - val_loss: 0.6376 - val_mse: 0.4134\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.6179 - mse: 0.3891 - val_loss: 0.6287 - val_mse: 0.4021\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 9s 87ms/step - loss: 0.6048 - mse: 0.3725 - val_loss: 0.6239 - val_mse: 0.3958\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.5949 - mse: 0.3606 - val_loss: 0.6200 - val_mse: 0.3908\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 9s 89ms/step - loss: 0.5869 - mse: 0.3502 - val_loss: 0.6168 - val_mse: 0.3868\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.5771 - mse: 0.3393 - val_loss: 0.6151 - val_mse: 0.3848\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.5682 - mse: 0.3292 - val_loss: 0.6182 - val_mse: 0.3886\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.5601 - mse: 0.3193 - val_loss: 0.6163 - val_mse: 0.3862\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.5526 - mse: 0.3116 - val_loss: 0.6143 - val_mse: 0.3839\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.5447 - mse: 0.3021 - val_loss: 0.6178 - val_mse: 0.3883\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.5370 - mse: 0.2938 - val_loss: 0.6104 - val_mse: 0.3794\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 9s 89ms/step - loss: 0.5286 - mse: 0.2851 - val_loss: 0.6261 - val_mse: 0.3990\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.5206 - mse: 0.2761 - val_loss: 0.6144 - val_mse: 0.3845\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 9s 88ms/step - loss: 0.5153 - mse: 0.2704 - val_loss: 0.6129 - val_mse: 0.3829\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.5090 - mse: 0.2648 - val_loss: 0.6091 - val_mse: 0.3786\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.5043 - mse: 0.2596 - val_loss: 0.6157 - val_mse: 0.3870\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.4980 - mse: 0.2532 - val_loss: 0.6139 - val_mse: 0.3843\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.4921 - mse: 0.2473 - val_loss: 0.6149 - val_mse: 0.3856\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4872 - mse: 0.2425 - val_loss: 0.6105 - val_mse: 0.3807\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4856 - mse: 0.2412 - val_loss: 0.6102 - val_mse: 0.3805\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4780 - mse: 0.2343 - val_loss: 0.6059 - val_mse: 0.3751\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.4770 - mse: 0.2321 - val_loss: 0.6043 - val_mse: 0.3733\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4753 - mse: 0.2314 - val_loss: 0.6057 - val_mse: 0.3745\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 9s 89ms/step - loss: 0.4705 - mse: 0.2260 - val_loss: 0.6127 - val_mse: 0.3833\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.4690 - mse: 0.2250 - val_loss: 0.6046 - val_mse: 0.3737\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4646 - mse: 0.2207 - val_loss: 0.6527 - val_mse: 0.4346\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4646 - mse: 0.2217 - val_loss: 0.6084 - val_mse: 0.3776\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4695 - mse: 0.2264 - val_loss: 0.6004 - val_mse: 0.3686\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4597 - mse: 0.2159 - val_loss: 0.6121 - val_mse: 0.3826\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4525 - mse: 0.2097 - val_loss: 0.6183 - val_mse: 0.3905\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4543 - mse: 0.2110 - val_loss: 0.6096 - val_mse: 0.3798\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4475 - mse: 0.2050 - val_loss: 0.6085 - val_mse: 0.3791\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 9s 92ms/step - loss: 0.4461 - mse: 0.2034 - val_loss: 0.6255 - val_mse: 0.3997\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4457 - mse: 0.2031 - val_loss: 0.6215 - val_mse: 0.3951\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4410 - mse: 0.1992 - val_loss: 0.6214 - val_mse: 0.3955\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4438 - mse: 0.2014 - val_loss: 0.6125 - val_mse: 0.3842\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 9s 91ms/step - loss: 0.4394 - mse: 0.1979 - val_loss: 0.6104 - val_mse: 0.3814\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 9s 90ms/step - loss: 0.4359 - mse: 0.1944 - val_loss: 0.6158 - val_mse: 0.3878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = padded_train, \n",
    "    y = Y_train, \n",
    "    validation_data = (padded_valid, Y_valid),\n",
    "    callbacks = callbacks,\n",
    "    epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['loss'], label = 'train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.box(False)\n",
    "plt.grid(True, alpha = .25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 18_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words= max_tokens)\n",
    "tokenized_train = tokenizer.texts_to_sequences(X_train.full_text)\n",
    "tokenized_valid = tokenizer.texts_to_sequences(X_valid.full_text)\n",
    "tokenized_test = tokenizer.texts_to_sequences(X_test.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train = pad_sequences(sequences=tokenized_train, maxlen = 1000)\n",
    "padded_valid = pad_sequences(sequences=tokenized_valid, maxlen = 1000)\n",
    "padded_test = pad_sequences(sequences=tokenized_test, maxlen = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3128, 1000), (587, 1000), (196, 1000))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape, padded_valid.shape, padded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector count: 400000\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(glove_path) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep = ' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Word vector count: {len(embeddings_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(tokenizer.word_index)\n",
    "embedding_matrix = np.zeros((max_tokens, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for word, i in tqdm(tokenizer.word_index.items()):\n",
    "    if i < num_words:\n",
    "        vect = embeddings_index.get(word, [])\n",
    "        if len(vect) > 0:\n",
    "            embedding_matrix[i] = vect[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: A 3D tensor, with shape [batch, timesteps, feature].\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim = max_tokens, \n",
    "        output_dim = 300,\n",
    "        embeddings_initializer = Constant(embedding_matrix),\n",
    "        input_length = 1000,\n",
    "        trainable = False),\n",
    "    tf.keras.layers.GRU(64, return_sequences=True),\n",
    "    tf.keras.layers.GRU(64, return_sequences=True),\n",
    "    tf.keras.layers.GRU(32, return_sequences=False),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdd_n/mambaforge/envs/tf_env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = MCRMSE, metrics = 'mse', optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 1000, 300)         5400000   \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 1000, 64)          70272     \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 1000, 64)          24960     \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 32)                9408      \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,504,838\n",
      "Trainable params: 104,838\n",
      "Non-trainable params: 5,400,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_scratch.keras\", save_best_only=True), \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = 50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 [==============================] - 9s 79ms/step - loss: 2.8847 - mse: 8.4474 - val_loss: 2.1668 - val_mse: 4.9505\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 7s 76ms/step - loss: 1.4002 - mse: 2.3047 - val_loss: 1.0407 - val_mse: 1.2126\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 7s 76ms/step - loss: 0.8471 - mse: 0.7684 - val_loss: 0.7238 - val_mse: 0.5325\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 7s 76ms/step - loss: 0.6719 - mse: 0.4595 - val_loss: 0.6527 - val_mse: 0.4329\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 8s 77ms/step - loss: 0.6497 - mse: 0.4297 - val_loss: 0.6495 - val_mse: 0.4288\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 7s 76ms/step - loss: 0.6494 - mse: 0.4292 - val_loss: 0.6493 - val_mse: 0.4286\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 7s 74ms/step - loss: 0.6498 - mse: 0.4292 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 7s 74ms/step - loss: 0.6487 - mse: 0.4290 - val_loss: 0.6489 - val_mse: 0.4280\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6484 - mse: 0.4290 - val_loss: 0.6490 - val_mse: 0.4281\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 8s 78ms/step - loss: 0.6494 - mse: 0.4291 - val_loss: 0.6489 - val_mse: 0.4281\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6494 - mse: 0.4291 - val_loss: 0.6497 - val_mse: 0.4289\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 0.6496 - mse: 0.4292 - val_loss: 0.6499 - val_mse: 0.4295\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6499 - mse: 0.4292 - val_loss: 0.6495 - val_mse: 0.4288\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6488 - mse: 0.4291 - val_loss: 0.6491 - val_mse: 0.4282\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6492 - mse: 0.4292 - val_loss: 0.6492 - val_mse: 0.4283\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6489 - mse: 0.4291 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 8s 78ms/step - loss: 0.6491 - mse: 0.4291 - val_loss: 0.6489 - val_mse: 0.4280\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 0.6494 - mse: 0.4291 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6493 - mse: 0.4290 - val_loss: 0.6497 - val_mse: 0.4291\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6496 - mse: 0.4291 - val_loss: 0.6496 - val_mse: 0.4290\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6494 - mse: 0.4291 - val_loss: 0.6497 - val_mse: 0.4292\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6493 - mse: 0.4292 - val_loss: 0.6494 - val_mse: 0.4286\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6487 - mse: 0.4289 - val_loss: 0.6501 - val_mse: 0.4297\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6501 - mse: 0.4293 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 0.6489 - mse: 0.4291 - val_loss: 0.6492 - val_mse: 0.4284\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 7s 74ms/step - loss: 0.6493 - mse: 0.4291 - val_loss: 0.6489 - val_mse: 0.4280\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6497 - mse: 0.4290 - val_loss: 0.6495 - val_mse: 0.4288\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6502 - mse: 0.4291 - val_loss: 0.6493 - val_mse: 0.4286\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6497 - mse: 0.4291 - val_loss: 0.6489 - val_mse: 0.4281\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6489 - mse: 0.4291 - val_loss: 0.6501 - val_mse: 0.4296\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6495 - mse: 0.4291 - val_loss: 0.6494 - val_mse: 0.4286\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 0.6498 - mse: 0.4292 - val_loss: 0.6491 - val_mse: 0.4282\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6501 - mse: 0.4291 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6489 - mse: 0.4290 - val_loss: 0.6491 - val_mse: 0.4282\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6497 - mse: 0.4292 - val_loss: 0.6492 - val_mse: 0.4283\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 7s 73ms/step - loss: 0.6490 - mse: 0.4288 - val_loss: 0.6501 - val_mse: 0.4295\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6497 - mse: 0.4291 - val_loss: 0.6500 - val_mse: 0.4295\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6487 - mse: 0.4292 - val_loss: 0.6497 - val_mse: 0.4290\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6493 - mse: 0.4291 - val_loss: 0.6491 - val_mse: 0.4283\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6490 - mse: 0.4291 - val_loss: 0.6492 - val_mse: 0.4283\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6490 - mse: 0.4291 - val_loss: 0.6496 - val_mse: 0.4290\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6486 - mse: 0.4291 - val_loss: 0.6494 - val_mse: 0.4286\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 0.6488 - mse: 0.4291 - val_loss: 0.6494 - val_mse: 0.4287\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6491 - mse: 0.4291 - val_loss: 0.6493 - val_mse: 0.4285\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6489 - mse: 0.4289 - val_loss: 0.6497 - val_mse: 0.4290\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6496 - mse: 0.4291 - val_loss: 0.6494 - val_mse: 0.4288\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 0.6482 - mse: 0.4290 - val_loss: 0.6496 - val_mse: 0.4291\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6501 - mse: 0.4292 - val_loss: 0.6492 - val_mse: 0.4283\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 0.6501 - mse: 0.4292 - val_loss: 0.6489 - val_mse: 0.4281\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 0.6496 - mse: 0.4290 - val_loss: 0.6497 - val_mse: 0.4291\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = padded_train, \n",
    "    y = Y_train, \n",
    "    validation_data = (padded_valid, Y_valid),\n",
    "    callbacks = callbacks,\n",
    "    epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['loss'], label = 'train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.box(False)\n",
    "plt.grid(True, alpha = .25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2813e3f799ffaf5677164940ac116feb5d9f74f8c095a47c658fbbe1fd1e4fc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
